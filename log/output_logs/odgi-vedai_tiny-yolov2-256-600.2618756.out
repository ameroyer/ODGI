Tensorflow version 1.10.1
968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold01
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold01
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold01_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold01_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold01_val
ODGI - vedai_fold01, Input size 256

   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB

Launch session:
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold01/tiny-yolov2_odgi_256_64/09-24_10-17
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold01/tiny-yolov2_odgi_256_64/09-24_10-17[0m

Start training:
  > Step 1 (epoch 1): loss = 17.11067
  > Step 251 (epoch 9): loss = 1.13413
val eval at step 500: map@0.50 = 0.00927 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.80190
  > Step 751 (epoch 25): loss = 0.62361
val eval at step 1000: map@0.50 = 0.08202 - map@0.75 = 0.00465
  > Step 1001 (epoch 34): loss = 0.61858
  > Step 1251 (epoch 42): loss = 0.62154
val eval at step 1500: map@0.50 = 0.14896 - map@0.75 = 0.00868
  > Step 1501 (epoch 50): loss = 0.71713
  > Step 1751 (epoch 58): loss = 0.67924
val eval at step 2000: map@0.50 = 0.18691 - map@0.75 = 0.03485
  > Step 2001 (epoch 67): loss = 0.56346
  > Step 2251 (epoch 75): loss = 0.56426
val eval at step 2500: map@0.50 = 0.20403 - map@0.75 = 0.01941
  > Step 2501 (epoch 83): loss = 0.49472
  > Step 2751 (epoch 91): loss = 0.57900
val eval at step 3000: map@0.50 = 0.24357 - map@0.75 = 0.04532
  > Step 3001 (epoch 100): loss = 0.43648
  > Step 3251 (epoch 108): loss = 0.44594
val eval at step 3500: map@0.50 = 0.14760 - map@0.75 = 0.02479
  > Step 3501 (epoch 116): loss = 0.64858
  > Step 3751 (epoch 125): loss = 0.50955
val eval at step 4000: map@0.50 = 0.27090 - map@0.75 = 0.04145
  > Step 4001 (epoch 133): loss = 0.42558
  > Step 4251 (epoch 141): loss = 0.37818
val eval at step 4500: map@0.50 = 0.28889 - map@0.75 = 0.07677
  > Step 4501 (epoch 149): loss = 0.38946
  > Step 4751 (epoch 158): loss = 0.35399
val eval at step 5000: map@0.50 = 0.34877 - map@0.75 = 0.09735
  > Step 5001 (epoch 166): loss = 0.31783
  > Step 5251 (epoch 174): loss = 0.40593
val eval at step 5500: map@0.50 = 0.33609 - map@0.75 = 0.05894
  > Step 5501 (epoch 182): loss = 0.43833
  > Step 5751 (epoch 191): loss = 0.68762
val eval at step 6000: map@0.50 = 0.36476 - map@0.75 = 0.09485
  > Step 6001 (epoch 199): loss = 0.34338
  > Step 6251 (epoch 207): loss = 0.36653
val eval at step 6500: map@0.50 = 0.34637 - map@0.75 = 0.07180
  > Step 6501 (epoch 215): loss = 0.42375
  > Step 6751 (epoch 224): loss = 0.26302
val eval at step 7000: map@0.50 = 0.37766 - map@0.75 = 0.10006
  > Step 7001 (epoch 232): loss = 0.33112
  > Step 7251 (epoch 240): loss = 0.30389
val eval at step 7500: map@0.50 = 0.36443 - map@0.75 = 0.11616
  > Step 7501 (epoch 248): loss = 0.32542
  > Step 7751 (epoch 257): loss = 0.31818
val eval at step 8000: map@0.50 = 0.38505 - map@0.75 = 0.08658
  > Step 8001 (epoch 265): loss = 0.28839
  > Step 8251 (epoch 273): loss = 0.33650
val eval at step 8500: map@0.50 = 0.46230 - map@0.75 = 0.12687
  > Step 8501 (epoch 282): loss = 0.25599
  > Step 8751 (epoch 290): loss = 0.42556
val eval at step 9000: map@0.50 = 0.40025 - map@0.75 = 0.09280
  > Step 9001 (epoch 298): loss = 0.37114
  > Step 9251 (epoch 306): loss = 0.25875
val eval at step 9500: map@0.50 = 0.46450 - map@0.75 = 0.11608
  > Step 9501 (epoch 315): loss = 0.27093
  > Step 9751 (epoch 323): loss = 0.24199
val eval at step 10000: map@0.50 = 0.41748 - map@0.75 = 0.12090
  > Step 10001 (epoch 331): loss = 0.27764
  > Step 10251 (epoch 339): loss = 0.23926
val eval at step 10500: map@0.50 = 0.40870 - map@0.75 = 0.09206
  > Step 10501 (epoch 348): loss = 0.19682
  > Step 10751 (epoch 356): loss = 0.32089
val eval at step 11000: map@0.50 = 0.32234 - map@0.75 = 0.08076
  > Step 11001 (epoch 364): loss = 0.36263
  > Step 11251 (epoch 372): loss = 0.28055
val eval at step 11500: map@0.50 = 0.37129 - map@0.75 = 0.11420
  > Step 11501 (epoch 381): loss = 0.24498
  > Step 11751 (epoch 389): loss = 0.24264
val eval at step 12000: map@0.50 = 0.44209 - map@0.75 = 0.10284
  > Step 12001 (epoch 397): loss = 0.21083
  > Step 12251 (epoch 405): loss = 0.22462
val eval at step 12500: map@0.50 = 0.40870 - map@0.75 = 0.05918
  > Step 12501 (epoch 414): loss = 0.21276
  > Step 12751 (epoch 422): loss = 0.23269
val eval at step 13000: map@0.50 = 0.40945 - map@0.75 = 0.12725
  > Step 13001 (epoch 430): loss = 0.22344
  > Step 13251 (epoch 439): loss = 0.20657
val eval at step 13500: map@0.50 = 0.44857 - map@0.75 = 0.09706
  > Step 13501 (epoch 447): loss = 0.19488
  > Step 13751 (epoch 455): loss = 0.27268
val eval at step 14000: map@0.50 = 0.41440 - map@0.75 = 0.15290
  > Step 14001 (epoch 463): loss = 0.18650
  > Step 14251 (epoch 472): loss = 0.17750
val eval at step 14500: map@0.50 = 0.40102 - map@0.75 = 0.15496
  > Step 14501 (epoch 480): loss = 0.22363
  > Step 14751 (epoch 488): loss = 0.21155
val eval at step 15000: map@0.50 = 0.44748 - map@0.75 = 0.15094
  > Step 15001 (epoch 496): loss = 0.22505
  > Step 15251 (epoch 505): loss = 0.17585
val eval at step 15500: map@0.50 = 0.42075 - map@0.75 = 0.12963
  > Step 15501 (epoch 513): loss = 0.16957
  > Step 15751 (epoch 521): loss = 0.16693
val eval at step 16000: map@0.50 = 0.43295 - map@0.75 = 0.13282
  > Step 16001 (epoch 529): loss = 0.21086
  > Step 16251 (epoch 538): loss = 0.16584
val eval at step 16500: map@0.50 = 0.40881 - map@0.75 = 0.11383
  > Step 16501 (epoch 546): loss = 0.30040
  > Step 16751 (epoch 554): loss = 0.16316
val eval at step 17000: map@0.50 = 0.44807 - map@0.75 = 0.15689
  > Step 17001 (epoch 563): loss = 0.18000
  > Step 17251 (epoch 571): loss = 0.13244
val eval at step 17500: map@0.50 = 0.44227 - map@0.75 = 0.14645
  > Step 17501 (epoch 579): loss = 0.18333
  > Step 17751 (epoch 587): loss = 0.16541
val eval at step 18000: map@0.50 = 0.42036 - map@0.75 = 0.18391
  > Step 18001 (epoch 596): loss = 0.20449
test eval at step 18150: map@0.50 = 0.42390 - map@0.75 = 0.18087
Tensorflow version 1.10.1
968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold02
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold02
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold02_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold02_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold02_val
ODGI - vedai_fold02, Input size 256

   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB

Launch session:
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold02/tiny-yolov2_odgi_256_64/09-24_13-03
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold02/tiny-yolov2_odgi_256_64/09-24_13-03[0m

Start training:
  > Step 1 (epoch 1): loss = 13.85262
  > Step 251 (epoch 9): loss = 1.03245
val eval at step 500: map@0.50 = 0.02135 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.78530
  > Step 751 (epoch 25): loss = 0.70121
val eval at step 1000: map@0.50 = 0.10264 - map@0.75 = 0.01705
  > Step 1001 (epoch 34): loss = 0.58908
  > Step 1251 (epoch 42): loss = 0.55645
val eval at step 1500: map@0.50 = 0.12705 - map@0.75 = 0.01419
  > Step 1501 (epoch 50): loss = 0.62066
  > Step 1751 (epoch 58): loss = 0.80730
val eval at step 2000: map@0.50 = 0.14615 - map@0.75 = 0.02051
  > Step 2001 (epoch 67): loss = 0.47916
  > Step 2251 (epoch 75): loss = 0.51112
val eval at step 2500: map@0.50 = 0.27143 - map@0.75 = 0.05022
  > Step 2501 (epoch 83): loss = 0.55706
  > Step 2751 (epoch 91): loss = 0.41665
val eval at step 3000: map@0.50 = 0.24584 - map@0.75 = 0.02493
  > Step 3001 (epoch 100): loss = 0.59784
  > Step 3251 (epoch 108): loss = 0.42903
val eval at step 3500: map@0.50 = 0.13541 - map@0.75 = 0.02300
  > Step 3501 (epoch 116): loss = 0.70962
  > Step 3751 (epoch 125): loss = 0.45582
val eval at step 4000: map@0.50 = 0.33003 - map@0.75 = 0.09517
  > Step 4001 (epoch 133): loss = 0.51524
  > Step 4251 (epoch 141): loss = 0.48943
val eval at step 4500: map@0.50 = 0.37280 - map@0.75 = 0.07249
  > Step 4501 (epoch 149): loss = 0.45750
  > Step 4751 (epoch 158): loss = 0.45634
val eval at step 5000: map@0.50 = 0.37778 - map@0.75 = 0.09909
  > Step 5001 (epoch 166): loss = 0.35783
  > Step 5251 (epoch 174): loss = 0.44000
val eval at step 5500: map@0.50 = 0.38154 - map@0.75 = 0.10233
  > Step 5501 (epoch 182): loss = 0.42399
  > Step 5751 (epoch 191): loss = 0.48234
val eval at step 6000: map@0.50 = 0.33470 - map@0.75 = 0.09400
  > Step 6001 (epoch 199): loss = 0.34160
  > Step 6251 (epoch 207): loss = 0.39728
val eval at step 6500: map@0.50 = 0.39917 - map@0.75 = 0.10192
  > Step 6501 (epoch 215): loss = 0.33058
  > Step 6751 (epoch 224): loss = 0.28912
val eval at step 7000: map@0.50 = 0.39777 - map@0.75 = 0.09284
  > Step 7001 (epoch 232): loss = 0.33283
Tensorflow version 1.10.1
968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold03
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold03
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold03_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold03_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold03_val
ODGI - vedai_fold03, Input size 256

   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.97 MB

Launch session:
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold03/tiny-yolov2_odgi_256_64/09-24_14-08
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold03/tiny-yolov2_odgi_256_64/09-24_14-08[0m

Start training:
  > Step 1 (epoch 1): loss = 22.03707
  > Step 251 (epoch 9): loss = 1.03774
val eval at step 500: map@0.50 = 0.03746 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.80684
  > Step 751 (epoch 25): loss = 0.62877
val eval at step 1000: map@0.50 = 0.03134 - map@0.75 = 0.00034
  > Step 1001 (epoch 34): loss = 0.61866
  > Step 1251 (epoch 42): loss = 0.56825
val eval at step 1500: map@0.50 = 0.05173 - map@0.75 = 0.01095
  > Step 1501 (epoch 50): loss = 0.54990
  > Step 1751 (epoch 58): loss = 0.52741
val eval at step 2000: map@0.50 = 0.09397 - map@0.75 = 0.01722
  > Step 2001 (epoch 67): loss = 0.53368
  > Step 2251 (epoch 75): loss = 0.58215
val eval at step 2500: map@0.50 = 0.11665 - map@0.75 = 0.01295
  > Step 2501 (epoch 83): loss = 0.46162
  > Step 2751 (epoch 91): loss = 0.61476
val eval at step 3000: map@0.50 = 0.15663 - map@0.75 = 0.03320
  > Step 3001 (epoch 100): loss = 0.48392
  > Step 3251 (epoch 108): loss = 0.44488
val eval at step 3500: map@0.50 = 0.15899 - map@0.75 = 0.02562
  > Step 3501 (epoch 116): loss = 0.45846
  > Step 3751 (epoch 125): loss = 0.42424
val eval at step 4000: map@0.50 = 0.18158 - map@0.75 = 0.02631
  > Step 4001 (epoch 133): loss = 0.35908
  > Step 4251 (epoch 141): loss = 0.42078
val eval at step 4500: map@0.50 = 0.19952 - map@0.75 = 0.04091
  > Step 4501 (epoch 149): loss = 0.49740
  > Step 4751 (epoch 158): loss = 0.52141
val eval at step 5000: map@0.50 = 0.19180 - map@0.75 = 0.04780
  > Step 5001 (epoch 166): loss = 0.37049
  > Step 5251 (epoch 174): loss = 0.35248
val eval at step 5500: map@0.50 = 0.18946 - map@0.75 = 0.03444
  > Step 5501 (epoch 182): loss = 0.34305
  > Step 5751 (epoch 191): loss = 0.37137
val eval at step 6000: map@0.50 = 0.21231 - map@0.75 = 0.04609
  > Step 6001 (epoch 199): loss = 0.38494
  > Step 6251 (epoch 207): loss = 0.31696
val eval at step 6500: map@0.50 = 0.20233 - map@0.75 = 0.03641
  > Step 6501 (epoch 215): loss = 0.34840
  > Step 6751 (epoch 224): loss = 0.37054
val eval at step 7000: map@0.50 = 0.24932 - map@0.75 = 0.03957
  > Step 7001 (epoch 232): loss = 0.32405
  > Step 7251 (epoch 240): loss = 0.78421
val eval at step 7500: map@0.50 = 0.23327 - map@0.75 = 0.04890
  > Step 7501 (epoch 248): loss = 0.38328
  > Step 7751 (epoch 257): loss = 0.28624
val eval at step 8000: map@0.50 = 0.21191 - map@0.75 = 0.04552
  > Step 8001 (epoch 265): loss = 0.28313
  > Step 8251 (epoch 273): loss = 0.23396
val eval at step 8500: map@0.50 = 0.22709 - map@0.75 = 0.08719
  > Step 8501 (epoch 282): loss = 0.25651
  > Step 8751 (epoch 290): loss = 0.25975
val eval at step 9000: map@0.50 = 0.22516 - map@0.75 = 0.05358
  > Step 9001 (epoch 298): loss = 0.24030
  > Step 9251 (epoch 306): loss = 0.30616
val eval at step 9500: map@0.50 = 0.28092 - map@0.75 = 0.10039
  > Step 9501 (epoch 315): loss = 0.24126
  > Step 9751 (epoch 323): loss = 0.28679
val eval at step 10000: map@0.50 = 0.26902 - map@0.75 = 0.06598
  > Step 10001 (epoch 331): loss = 0.25374
  > Step 10251 (epoch 339): loss = 0.25379
val eval at step 10500: map@0.50 = 0.25188 - map@0.75 = 0.07591
  > Step 10501 (epoch 348): loss = 0.20536
  > Step 10751 (epoch 356): loss = 0.24184
val eval at step 11000: map@0.50 = 0.26305 - map@0.75 = 0.06019
  > Step 11001 (epoch 364): loss = 0.24851
  > Step 11251 (epoch 372): loss = 0.23787
val eval at step 11500: map@0.50 = 0.30226 - map@0.75 = 0.09477
  > Step 11501 (epoch 381): loss = 0.22720
  > Step 11751 (epoch 389): loss = 0.25036
val eval at step 12000: map@0.50 = 0.16032 - map@0.75 = 0.03202
  > Step 12001 (epoch 397): loss = 0.68809
  > Step 12251 (epoch 405): loss = 0.27317
val eval at step 12500: map@0.50 = 0.30223 - map@0.75 = 0.09689
  > Step 12501 (epoch 414): loss = 0.24694
  > Step 12751 (epoch 422): loss = 0.22653
val eval at step 13000: map@0.50 = 0.30648 - map@0.75 = 0.09649
  > Step 13001 (epoch 430): loss = 0.19678
  > Step 13251 (epoch 439): loss = 0.18055
val eval at step 13500: map@0.50 = 0.32238 - map@0.75 = 0.07955
  > Step 13501 (epoch 447): loss = 0.21183
  > Step 13751 (epoch 455): loss = 0.17769
val eval at step 14000: map@0.50 = 0.28998 - map@0.75 = 0.06606
  > Step 14001 (epoch 463): loss = 0.17991
  > Step 14251 (epoch 472): loss = 0.16849
val eval at step 14500: map@0.50 = 0.29323 - map@0.75 = 0.06234
  > Step 14501 (epoch 480): loss = 0.21389
  > Step 14751 (epoch 488): loss = 0.19996
val eval at step 15000: map@0.50 = 0.28254 - map@0.75 = 0.12603
  > Step 15001 (epoch 496): loss = 0.22133
  > Step 15251 (epoch 505): loss = 0.18205
val eval at step 15500: map@0.50 = 0.25659 - map@0.75 = 0.09022
  > Step 15501 (epoch 513): loss = 0.21798
  > Step 15751 (epoch 521): loss = 0.17461
val eval at step 16000: map@0.50 = 0.30057 - map@0.75 = 0.06804
  > Step 16001 (epoch 529): loss = 0.14702
  > Step 16251 (epoch 538): loss = 0.17718
val eval at step 16500: map@0.50 = 0.31307 - map@0.75 = 0.13140
  > Step 16501 (epoch 546): loss = 0.29825
  > Step 16751 (epoch 554): loss = 0.20005
val eval at step 17000: map@0.50 = 0.31142 - map@0.75 = 0.10138
  > Step 17001 (epoch 563): loss = 0.20548
  > Step 17251 (epoch 571): loss = 0.13789
val eval at step 17500: map@0.50 = 0.30134 - map@0.75 = 0.11175
  > Step 17501 (epoch 579): loss = 0.15359
  > Step 17751 (epoch 587): loss = 0.14565
val eval at step 18000: map@0.50 = 0.32927 - map@0.75 = 0.07865
  > Step 18001 (epoch 596): loss = 0.15490
test eval at step 18150: map@0.50 = 0.25873 - map@0.75 = 0.07576
Tensorflow version 1.10.1
968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold04
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold04
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold04_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold04_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold04_val
ODGI - vedai_fold04, Input size 256

   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB

Launch session:
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold04/tiny-yolov2_odgi_256_64/09-24_16-55
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold04/tiny-yolov2_odgi_256_64/09-24_16-55[0m

Start training:
  > Step 1 (epoch 1): loss = 19.54877
  > Step 251 (epoch 9): loss = 2.34784
val eval at step 500: map@0.50 = 0.00272 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 1.97867
  > Step 751 (epoch 25): loss = 0.77016
val eval at step 1000: map@0.50 = 0.04751 - map@0.75 = 0.00007
  > Step 1001 (epoch 34): loss = 0.71935
  > Step 1251 (epoch 42): loss = 0.72463
val eval at step 1500: map@0.50 = 0.11877 - map@0.75 = 0.00882
  > Step 1501 (epoch 50): loss = 0.74519
  > Step 1751 (epoch 58): loss = 0.85585
val eval at step 2000: map@0.50 = 0.13910 - map@0.75 = 0.02028
  > Step 2001 (epoch 67): loss = 0.73800
  > Step 2251 (epoch 75): loss = 0.55438
val eval at step 2500: map@0.50 = 0.21403 - map@0.75 = 0.03912
  > Step 2501 (epoch 83): loss = 0.50898
  > Step 2751 (epoch 91): loss = 0.58859
val eval at step 3000: map@0.50 = 0.10055 - map@0.75 = 0.01221
  > Step 3001 (epoch 100): loss = 0.66667
  > Step 3251 (epoch 108): loss = 0.47740
val eval at step 3500: map@0.50 = 0.21322 - map@0.75 = 0.01986
  > Step 3501 (epoch 116): loss = 0.45786
  > Step 3751 (epoch 125): loss = 0.43284
Tensorflow version 1.10.1
968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold05
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold05
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold05_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold05_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold05_val
ODGI - vedai_fold05, Input size 256

   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB

Launch session:
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold05/tiny-yolov2_odgi_256_64/09-24_17-31
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold05/tiny-yolov2_odgi_256_64/09-24_17-31[0m

Start training:
  > Step 1 (epoch 1): loss = 10.97866
  > Step 251 (epoch 9): loss = 1.09135
val eval at step 500: map@0.50 = 0.00861 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.83045
  > Step 751 (epoch 25): loss = 0.70254
val eval at step 1000: map@0.50 = 0.06570 - map@0.75 = 0.00275
  > Step 1001 (epoch 34): loss = 0.65305
  > Step 1251 (epoch 42): loss = 0.67527
val eval at step 1500: map@0.50 = 0.07792 - map@0.75 = 0.00620
  > Step 1501 (epoch 50): loss = 0.59212
  > Step 1751 (epoch 58): loss = 0.56089
val eval at step 2000: map@0.50 = 0.15600 - map@0.75 = 0.01017
  > Step 2001 (epoch 67): loss = 0.57724
  > Step 2251 (epoch 75): loss = 0.51702
val eval at step 2500: map@0.50 = 0.18646 - map@0.75 = 0.00523
  > Step 2501 (epoch 83): loss = 0.56906
  > Step 2751 (epoch 91): loss = 0.75127
val eval at step 3000: map@0.50 = 0.15094 - map@0.75 = 0.02738
  > Step 3001 (epoch 100): loss = 0.55236
  > Step 3251 (epoch 108): loss = 0.48423
val eval at step 3500: map@0.50 = 0.19064 - map@0.75 = 0.02309
  > Step 3501 (epoch 116): loss = 0.50465
  > Step 3751 (epoch 125): loss = 0.44841
val eval at step 4000: map@0.50 = 0.25293 - map@0.75 = 0.03431
  > Step 4001 (epoch 133): loss = 0.42850
  > Step 4251 (epoch 141): loss = 0.46604
val eval at step 4500: map@0.50 = 0.27030 - map@0.75 = 0.06255
  > Step 4501 (epoch 149): loss = 0.44464
  > Step 4751 (epoch 158): loss = 0.39544
val eval at step 5000: map@0.50 = 0.26744 - map@0.75 = 0.05130
  > Step 5001 (epoch 166): loss = 0.47488
  > Step 5251 (epoch 174): loss = 0.52468
val eval at step 5500: map@0.50 = 0.30157 - map@0.75 = 0.08397
  > Step 5501 (epoch 182): loss = 0.48493
  > Step 5751 (epoch 191): loss = 0.39470
val eval at step 6000: map@0.50 = 0.32543 - map@0.75 = 0.07459
  > Step 6001 (epoch 199): loss = 0.35918
  > Step 6251 (epoch 207): loss = 0.34353
val eval at step 6500: map@0.50 = 0.33257 - map@0.75 = 0.09373
  > Step 6501 (epoch 215): loss = 0.36809
  > Step 6751 (epoch 224): loss = 0.32658
val eval at step 7000: map@0.50 = 0.21654 - map@0.75 = 0.04999
  > Step 7001 (epoch 232): loss = 0.49762
  > Step 7251 (epoch 240): loss = 0.45320
val eval at step 7500: map@0.50 = 0.35961 - map@0.75 = 0.07921
  > Step 7501 (epoch 248): loss = 0.34915
  > Step 7751 (epoch 257): loss = 0.29527
val eval at step 8000: map@0.50 = 0.39043 - map@0.75 = 0.08798
  > Step 8001 (epoch 265): loss = 0.35712
  > Step 8251 (epoch 273): loss = 0.29330
val eval at step 8500: map@0.50 = 0.30548 - map@0.75 = 0.04020
  > Step 8501 (epoch 282): loss = 0.27653
  > Step 8751 (epoch 290): loss = 0.33763
val eval at step 9000: map@0.50 = 0.36015 - map@0.75 = 0.04993
  > Step 9001 (epoch 298): loss = 0.30209
  > Step 9251 (epoch 306): loss = 0.30027
val eval at step 9500: map@0.50 = 0.39282 - map@0.75 = 0.07402
  > Step 9501 (epoch 315): loss = 0.26001
  > Step 9751 (epoch 323): loss = 0.28924
val eval at step 10000: map@0.50 = 0.43633 - map@0.75 = 0.12624
  > Step 10001 (epoch 331): loss = 0.25116
  > Step 10251 (epoch 339): loss = 0.30490
Tensorflow version 1.10.1
ODGI - vedai_fold06, Input size 256

968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold06
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold06
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold06_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold06_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold06_val
   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold06/tiny-yolov2_odgi_256_64/09-24_19-05

Launch session:
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold06/tiny-yolov2_odgi_256_64/09-24_19-05[0m

Start training:
  > Step 1 (epoch 1): loss = 20.38508
  > Step 251 (epoch 9): loss = 1.13853
val eval at step 500: map@0.50 = 0.02525 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.78656
  > Step 751 (epoch 25): loss = 0.68163
val eval at step 1000: map@0.50 = 0.07001 - map@0.75 = 0.00744
  > Step 1001 (epoch 34): loss = 0.57893
  > Step 1251 (epoch 42): loss = 0.64763
val eval at step 1500: map@0.50 = 0.13536 - map@0.75 = 0.01023
  > Step 1501 (epoch 50): loss = 0.59312
  > Step 1751 (epoch 58): loss = 0.57111
val eval at step 2000: map@0.50 = 0.16229 - map@0.75 = 0.01495
  > Step 2001 (epoch 67): loss = 0.49832
  > Step 2251 (epoch 75): loss = 0.55845
val eval at step 2500: map@0.50 = 0.17813 - map@0.75 = 0.01776
  > Step 2501 (epoch 83): loss = 0.52845
  > Step 2751 (epoch 91): loss = 0.46203
val eval at step 3000: map@0.50 = 0.21113 - map@0.75 = 0.04159
  > Step 3001 (epoch 100): loss = 0.44859
  > Step 3251 (epoch 108): loss = 0.50246
val eval at step 3500: map@0.50 = 0.13669 - map@0.75 = 0.00265
  > Step 3501 (epoch 116): loss = 0.73007
  > Step 3751 (epoch 125): loss = 0.42632
val eval at step 4000: map@0.50 = 0.27201 - map@0.75 = 0.08617
  > Step 4001 (epoch 133): loss = 0.43143
  > Step 4251 (epoch 141): loss = 0.33411
val eval at step 4500: map@0.50 = 0.27792 - map@0.75 = 0.02391
  > Step 4501 (epoch 149): loss = 0.43817
  > Step 4751 (epoch 158): loss = 0.36691
val eval at step 5000: map@0.50 = 0.33557 - map@0.75 = 0.04860
  > Step 5001 (epoch 166): loss = 0.37039
  > Step 5251 (epoch 174): loss = 0.37640
val eval at step 5500: map@0.50 = 0.24036 - map@0.75 = 0.05749
  > Step 5501 (epoch 182): loss = 0.69400
  > Step 5751 (epoch 191): loss = 0.40081
val eval at step 6000: map@0.50 = 0.37587 - map@0.75 = 0.09674
  > Step 6001 (epoch 199): loss = 0.35134
  > Step 6251 (epoch 207): loss = 0.27561
val eval at step 6500: map@0.50 = 0.34456 - map@0.75 = 0.06851
  > Step 6501 (epoch 215): loss = 0.38296
  > Step 6751 (epoch 224): loss = 0.31406
val eval at step 7000: map@0.50 = 0.36990 - map@0.75 = 0.07454
  > Step 7001 (epoch 232): loss = 0.27132
  > Step 7251 (epoch 240): loss = 0.32697
val eval at step 7500: map@0.50 = 0.36789 - map@0.75 = 0.10395
  > Step 7501 (epoch 248): loss = 0.31056
  > Step 7751 (epoch 257): loss = 0.31903
val eval at step 8000: map@0.50 = 0.40077 - map@0.75 = 0.11650
  > Step 8001 (epoch 265): loss = 0.42638
  > Step 8251 (epoch 273): loss = 0.31014
val eval at step 8500: map@0.50 = 0.42796 - map@0.75 = 0.14207
  > Step 8501 (epoch 282): loss = 0.27835
  > Step 8751 (epoch 290): loss = 0.25054
val eval at step 9000: map@0.50 = 0.37996 - map@0.75 = 0.09176
  > Step 9001 (epoch 298): loss = 0.29705
  > Step 9251 (epoch 306): loss = 0.29543
val eval at step 9500: map@0.50 = 0.38379 - map@0.75 = 0.11100
  > Step 9501 (epoch 315): loss = 0.20644
  > Step 9751 (epoch 323): loss = 0.26258
val eval at step 10000: map@0.50 = 0.42013 - map@0.75 = 0.09769
  > Step 10001 (epoch 331): loss = 0.22832
  > Step 10251 (epoch 339): loss = 0.25105
val eval at step 10500: map@0.50 = 0.41393 - map@0.75 = 0.09204
  > Step 10501 (epoch 348): loss = 0.23192
  > Step 10751 (epoch 356): loss = 0.27357
val eval at step 11000: map@0.50 = 0.45189 - map@0.75 = 0.09456
  > Step 11001 (epoch 364): loss = 0.22079
  > Step 11251 (epoch 372): loss = 0.52107
val eval at step 11500: map@0.50 = 0.38336 - map@0.75 = 0.13426
  > Step 11501 (epoch 381): loss = 0.25803
  > Step 11751 (epoch 389): loss = 0.21019
val eval at step 12000: map@0.50 = 0.42672 - map@0.75 = 0.13859
  > Step 12001 (epoch 397): loss = 0.21433
  > Step 12251 (epoch 405): loss = 0.18365
val eval at step 12500: map@0.50 = 0.37728 - map@0.75 = 0.08364
  > Step 12501 (epoch 414): loss = 0.18080
  > Step 12751 (epoch 422): loss = 0.17952
val eval at step 13000: map@0.50 = 0.37545 - map@0.75 = 0.11319
  > Step 13001 (epoch 430): loss = 0.19002
  > Step 13251 (epoch 439): loss = 0.14798
val eval at step 13500: map@0.50 = 0.39747 - map@0.75 = 0.10805
  > Step 13501 (epoch 447): loss = 0.23183
  > Step 13751 (epoch 455): loss = 0.18778
val eval at step 14000: map@0.50 = 0.40226 - map@0.75 = 0.13270
  > Step 14001 (epoch 463): loss = 0.19177
  > Step 14251 (epoch 472): loss = 0.15440
val eval at step 14500: map@0.50 = 0.42024 - map@0.75 = 0.11172
  > Step 14501 (epoch 480): loss = 0.19073
  > Step 14751 (epoch 488): loss = 0.24346
val eval at step 15000: map@0.50 = 0.37689 - map@0.75 = 0.11772
  > Step 15001 (epoch 496): loss = 0.47018
  > Step 15251 (epoch 505): loss = 0.22559
val eval at step 15500: map@0.50 = 0.43437 - map@0.75 = 0.13955
  > Step 15501 (epoch 513): loss = 0.17760
  > Step 15751 (epoch 521): loss = 0.17364
val eval at step 16000: map@0.50 = 0.42525 - map@0.75 = 0.10014
  > Step 16001 (epoch 529): loss = 0.19074
  > Step 16251 (epoch 538): loss = 0.16866
val eval at step 16500: map@0.50 = 0.39692 - map@0.75 = 0.10805
  > Step 16501 (epoch 546): loss = 0.16845
  > Step 16751 (epoch 554): loss = 0.18151
val eval at step 17000: map@0.50 = 0.40773 - map@0.75 = 0.11753
  > Step 17001 (epoch 563): loss = 0.20518
  > Step 17251 (epoch 571): loss = 0.16098
val eval at step 17500: map@0.50 = 0.38322 - map@0.75 = 0.11042
  > Step 17501 (epoch 579): loss = 0.14529
  > Step 17751 (epoch 587): loss = 0.19705
val eval at step 18000: map@0.50 = 0.43428 - map@0.75 = 0.13138
  > Step 18001 (epoch 596): loss = 0.14817
test eval at step 18150: map@0.50 = 0.35489 - map@0.75 = 0.10352
Tensorflow version 1.10.1
ODGI - vedai_fold07, Input size 256

968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold07
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold07
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold07_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold07_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold07_val
   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold07/tiny-yolov2_odgi_256_64/09-24_21-51

Launch session:
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold07/tiny-yolov2_odgi_256_64/09-24_21-51[0m

Start training:
  > Step 1 (epoch 1): loss = 20.23444
  > Step 251 (epoch 9): loss = 1.07408
val eval at step 500: map@0.50 = 0.02216 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.84751
  > Step 751 (epoch 25): loss = 0.73054
val eval at step 1000: map@0.50 = 0.07530 - map@0.75 = 0.00359
  > Step 1001 (epoch 34): loss = 0.65962
  > Step 1251 (epoch 42): loss = 0.65643
val eval at step 1500: map@0.50 = 0.10999 - map@0.75 = 0.01361
  > Step 1501 (epoch 50): loss = 0.59287
  > Step 1751 (epoch 58): loss = 0.66856
val eval at step 2000: map@0.50 = 0.15183 - map@0.75 = 0.01563
  > Step 2001 (epoch 67): loss = 0.60551
  > Step 2251 (epoch 75): loss = 0.53064
val eval at step 2500: map@0.50 = 0.19665 - map@0.75 = 0.02272
  > Step 2501 (epoch 83): loss = 0.50248
  > Step 2751 (epoch 91): loss = 0.47360
val eval at step 3000: map@0.50 = 0.22199 - map@0.75 = 0.02701
  > Step 3001 (epoch 100): loss = 0.47429
  > Step 3251 (epoch 108): loss = 0.51744
val eval at step 3500: map@0.50 = 0.21118 - map@0.75 = 0.04388
  > Step 3501 (epoch 116): loss = 0.51485
  > Step 3751 (epoch 125): loss = 0.44763
val eval at step 4000: map@0.50 = 0.28802 - map@0.75 = 0.06494
  > Step 4001 (epoch 133): loss = 0.40795
  > Step 4251 (epoch 141): loss = 0.39713
val eval at step 4500: map@0.50 = 0.29164 - map@0.75 = 0.06751
  > Step 4501 (epoch 149): loss = 0.35373
  > Step 4751 (epoch 158): loss = 0.38142
val eval at step 5000: map@0.50 = 0.27830 - map@0.75 = 0.04205
  > Step 5001 (epoch 166): loss = 0.37977
  > Step 5251 (epoch 174): loss = 0.39268
val eval at step 5500: map@0.50 = 0.14447 - map@0.75 = 0.03045
  > Step 5501 (epoch 182): loss = 0.65193
  > Step 5751 (epoch 191): loss = 0.34157
val eval at step 6000: map@0.50 = 0.32906 - map@0.75 = 0.04387
  > Step 6001 (epoch 199): loss = 0.37681
  > Step 6251 (epoch 207): loss = 0.37118
val eval at step 6500: map@0.50 = 0.33889 - map@0.75 = 0.09193
  > Step 6501 (epoch 215): loss = 0.32438
  > Step 6751 (epoch 224): loss = 0.31281
val eval at step 7000: map@0.50 = 0.34000 - map@0.75 = 0.07831
  > Step 7001 (epoch 232): loss = 0.30330
  > Step 7251 (epoch 240): loss = 0.31918
val eval at step 7500: map@0.50 = 0.34423 - map@0.75 = 0.09308
  > Step 7501 (epoch 248): loss = 0.33341
  > Step 7751 (epoch 257): loss = 0.44826
val eval at step 8000: map@0.50 = 0.31343 - map@0.75 = 0.10425
  > Step 8001 (epoch 265): loss = 0.43510
  > Step 8251 (epoch 273): loss = 0.28497
val eval at step 8500: map@0.50 = 0.36506 - map@0.75 = 0.06742
  > Step 8501 (epoch 282): loss = 0.27226
  > Step 8751 (epoch 290): loss = 0.29152
val eval at step 9000: map@0.50 = 0.37125 - map@0.75 = 0.07565
  > Step 9001 (epoch 298): loss = 0.30588
  > Step 9251 (epoch 306): loss = 0.26337
val eval at step 9500: map@0.50 = 0.34659 - map@0.75 = 0.07587
  > Step 9501 (epoch 315): loss = 0.26523
  > Step 9751 (epoch 323): loss = 0.24425
val eval at step 10000: map@0.50 = 0.37210 - map@0.75 = 0.07399
  > Step 10001 (epoch 331): loss = 0.26632
  > Step 10251 (epoch 339): loss = 0.25036
val eval at step 10500: map@0.50 = 0.38966 - map@0.75 = 0.07700
  > Step 10501 (epoch 348): loss = 0.21886
  > Step 10751 (epoch 356): loss = 0.25037
val eval at step 11000: map@0.50 = 0.37009 - map@0.75 = 0.10594
  > Step 11001 (epoch 364): loss = 0.23327
  > Step 11251 (epoch 372): loss = 0.22032
val eval at step 11500: map@0.50 = 0.36249 - map@0.75 = 0.10237
  > Step 11501 (epoch 381): loss = 0.21214
  > Step 11751 (epoch 389): loss = 0.25622
val eval at step 12000: map@0.50 = 0.35234 - map@0.75 = 0.10664
  > Step 12001 (epoch 397): loss = 0.29714
  > Step 12251 (epoch 405): loss = 0.34955
val eval at step 12500: map@0.50 = 0.39890 - map@0.75 = 0.10712
  > Step 12501 (epoch 414): loss = 0.19041
  > Step 12751 (epoch 422): loss = 0.18700
val eval at step 13000: map@0.50 = 0.34418 - map@0.75 = 0.08202
  > Step 13001 (epoch 430): loss = 0.19063
  > Step 13251 (epoch 439): loss = 0.17618
val eval at step 13500: map@0.50 = 0.38969 - map@0.75 = 0.11485
  > Step 13501 (epoch 447): loss = 0.20372
  > Step 13751 (epoch 455): loss = 0.22271
val eval at step 14000: map@0.50 = 0.36920 - map@0.75 = 0.12997
  > Step 14001 (epoch 463): loss = 0.20494
  > Step 14251 (epoch 472): loss = 0.18436
val eval at step 14500: map@0.50 = 0.36312 - map@0.75 = 0.10092
  > Step 14501 (epoch 480): loss = 0.24247
  > Step 14751 (epoch 488): loss = 0.17733
val eval at step 15000: map@0.50 = 0.41267 - map@0.75 = 0.13268
  > Step 15001 (epoch 496): loss = 0.21379
  > Step 15251 (epoch 505): loss = 0.18133
val eval at step 15500: map@0.50 = 0.35746 - map@0.75 = 0.10527
  > Step 15501 (epoch 513): loss = 0.17130
  > Step 15751 (epoch 521): loss = 0.17241
val eval at step 16000: map@0.50 = 0.40881 - map@0.75 = 0.12563
  > Step 16001 (epoch 529): loss = 0.23435
  > Step 16251 (epoch 538): loss = 0.31867
val eval at step 16500: map@0.50 = 0.38243 - map@0.75 = 0.08579
  > Step 16501 (epoch 546): loss = 0.20860
  > Step 16751 (epoch 554): loss = 0.19343
val eval at step 17000: map@0.50 = 0.36022 - map@0.75 = 0.09766
  > Step 17001 (epoch 563): loss = 0.14734
  > Step 17251 (epoch 571): loss = 0.17678
val eval at step 17500: map@0.50 = 0.36865 - map@0.75 = 0.05846
  > Step 17501 (epoch 579): loss = 0.14914
  > Step 17751 (epoch 587): loss = 0.11800
val eval at step 18000: map@0.50 = 0.34032 - map@0.75 = 0.09806
  > Step 18001 (epoch 596): loss = 0.14552
test eval at step 18150: map@0.50 = 0.34780 - map@0.75 = 0.07329
Tensorflow version 1.10.1
ODGI - vedai_fold08, Input size 256

968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold08
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold08
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold08_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold08_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold08_val
   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold08/tiny-yolov2_odgi_256_64/09-25_00-38

Launch session:
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold08/tiny-yolov2_odgi_256_64/09-25_00-38[0m

Start training:
  > Step 1 (epoch 1): loss = 12.38514
  > Step 251 (epoch 9): loss = 1.20440
val eval at step 500: map@0.50 = 0.00000 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.87950
  > Step 751 (epoch 25): loss = 0.62498
val eval at step 1000: map@0.50 = 0.04734 - map@0.75 = 0.00487
  > Step 1001 (epoch 34): loss = 0.63707
  > Step 1251 (epoch 42): loss = 0.59849
val eval at step 1500: map@0.50 = 0.07102 - map@0.75 = 0.02066
  > Step 1501 (epoch 50): loss = 0.70686
  > Step 1751 (epoch 58): loss = 0.58617
val eval at step 2000: map@0.50 = 0.08296 - map@0.75 = 0.01143
  > Step 2001 (epoch 67): loss = 0.68359
  > Step 2251 (epoch 75): loss = 0.56794
val eval at step 2500: map@0.50 = 0.13169 - map@0.75 = 0.02897
  > Step 2501 (epoch 83): loss = 0.45340
  > Step 2751 (epoch 91): loss = 0.52140
val eval at step 3000: map@0.50 = 0.14502 - map@0.75 = 0.03161
  > Step 3001 (epoch 100): loss = 0.66911
  > Step 3251 (epoch 108): loss = 0.47972
val eval at step 3500: map@0.50 = 0.12919 - map@0.75 = 0.01911
  > Step 3501 (epoch 116): loss = 0.53769
  > Step 3751 (epoch 125): loss = 0.52211
val eval at step 4000: map@0.50 = 0.27363 - map@0.75 = 0.03898
  > Step 4001 (epoch 133): loss = 0.46132
  > Step 4251 (epoch 141): loss = 0.39381
val eval at step 4500: map@0.50 = 0.26685 - map@0.75 = 0.04000
  > Step 4501 (epoch 149): loss = 0.37046
  > Step 4751 (epoch 158): loss = 0.29647
val eval at step 5000: map@0.50 = 0.26059 - map@0.75 = 0.03522
  > Step 5001 (epoch 166): loss = 0.41594
  > Step 5251 (epoch 174): loss = 0.37962
val eval at step 5500: map@0.50 = 0.25361 - map@0.75 = 0.05191
  > Step 5501 (epoch 182): loss = 0.39793
  > Step 5751 (epoch 191): loss = 0.41014
val eval at step 6000: map@0.50 = 0.28122 - map@0.75 = 0.05442
  > Step 6001 (epoch 199): loss = 0.41131
  > Step 6251 (epoch 207): loss = 0.48954
val eval at step 6500: map@0.50 = 0.27643 - map@0.75 = 0.02739
  > Step 6501 (epoch 215): loss = 0.41496
  > Step 6751 (epoch 224): loss = 0.34283
val eval at step 7000: map@0.50 = 0.32620 - map@0.75 = 0.07030
  > Step 7001 (epoch 232): loss = 0.28032
  > Step 7251 (epoch 240): loss = 0.31451
val eval at step 7500: map@0.50 = 0.33721 - map@0.75 = 0.06913
  > Step 7501 (epoch 248): loss = 0.31758
  > Step 7751 (epoch 257): loss = 0.28728
val eval at step 8000: map@0.50 = 0.30558 - map@0.75 = 0.05888
  > Step 8001 (epoch 265): loss = 0.32348
  > Step 8251 (epoch 273): loss = 0.25609
val eval at step 8500: map@0.50 = 0.31806 - map@0.75 = 0.05001
  > Step 8501 (epoch 282): loss = 0.28000
  > Step 8751 (epoch 290): loss = 0.28396
val eval at step 9000: map@0.50 = 0.38272 - map@0.75 = 0.08615
  > Step 9001 (epoch 298): loss = 0.30074
  > Step 9251 (epoch 306): loss = 0.49292
val eval at step 9500: map@0.50 = 0.35488 - map@0.75 = 0.08273
  > Step 9501 (epoch 315): loss = 0.30701
  > Step 9751 (epoch 323): loss = 0.23281
val eval at step 10000: map@0.50 = 0.38111 - map@0.75 = 0.08990
  > Step 10001 (epoch 331): loss = 0.26289
  > Step 10251 (epoch 339): loss = 0.17898
val eval at step 10500: map@0.50 = 0.36837 - map@0.75 = 0.10250
  > Step 10501 (epoch 348): loss = 0.21106
  > Step 10751 (epoch 356): loss = 0.21672
val eval at step 11000: map@0.50 = 0.34099 - map@0.75 = 0.08245
  > Step 11001 (epoch 364): loss = 0.27774
  > Step 11251 (epoch 372): loss = 0.23016
val eval at step 11500: map@0.50 = 0.33889 - map@0.75 = 0.08974
  > Step 11501 (epoch 381): loss = 0.25278
  > Step 11751 (epoch 389): loss = 0.28533
val eval at step 12000: map@0.50 = 0.39982 - map@0.75 = 0.10844
  > Step 12001 (epoch 397): loss = 0.22516
  > Step 12251 (epoch 405): loss = 0.21177
val eval at step 12500: map@0.50 = 0.37169 - map@0.75 = 0.08576
  > Step 12501 (epoch 414): loss = 0.20632
  > Step 12751 (epoch 422): loss = 0.21400
val eval at step 13000: map@0.50 = 0.37837 - map@0.75 = 0.09083
  > Step 13001 (epoch 430): loss = 0.22580
  > Step 13251 (epoch 439): loss = 0.69543
val eval at step 13500: map@0.50 = 0.35449 - map@0.75 = 0.05053
  > Step 13501 (epoch 447): loss = 0.28248
  > Step 13751 (epoch 455): loss = 0.19392
val eval at step 14000: map@0.50 = 0.37639 - map@0.75 = 0.09457
  > Step 14001 (epoch 463): loss = 0.24096
  > Step 14251 (epoch 472): loss = 0.20717
val eval at step 14500: map@0.50 = 0.35365 - map@0.75 = 0.10194
  > Step 14501 (epoch 480): loss = 0.22251
  > Step 14751 (epoch 488): loss = 0.16852
val eval at step 15000: map@0.50 = 0.40995 - map@0.75 = 0.12424
  > Step 15001 (epoch 496): loss = 0.17114
  > Step 15251 (epoch 505): loss = 0.18254
val eval at step 15500: map@0.50 = 0.38153 - map@0.75 = 0.07707
  > Step 15501 (epoch 513): loss = 0.19946
  > Step 15751 (epoch 521): loss = 0.19159
val eval at step 16000: map@0.50 = 0.34812 - map@0.75 = 0.09952
  > Step 16001 (epoch 529): loss = 0.17461
  > Step 16251 (epoch 538): loss = 0.19992
val eval at step 16500: map@0.50 = 0.39264 - map@0.75 = 0.10917
  > Step 16501 (epoch 546): loss = 0.17369
  > Step 16751 (epoch 554): loss = 0.15272
val eval at step 17000: map@0.50 = 0.38700 - map@0.75 = 0.09167
  > Step 17001 (epoch 563): loss = 0.20451
  > Step 17251 (epoch 571): loss = 0.15540
val eval at step 17500: map@0.50 = 0.39318 - map@0.75 = 0.09605
  > Step 17501 (epoch 579): loss = 0.15793
  > Step 17751 (epoch 587): loss = 0.20810
val eval at step 18000: map@0.50 = 0.39226 - map@0.75 = 0.10548
  > Step 18001 (epoch 596): loss = 0.25332
test eval at step 18150: map@0.50 = 0.34628 - map@0.75 = 0.09757
Tensorflow version 1.10.1
ODGI - vedai_fold09, Input size 256

968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold09
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold09
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold09_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold09_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold09_val
   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold09/tiny-yolov2_odgi_256_64/09-25_03-26

Launch session:
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold09/tiny-yolov2_odgi_256_64/09-25_03-26[0m

Start training:
  > Step 1 (epoch 1): loss = 22.52449
  > Step 251 (epoch 9): loss = 1.30213
val eval at step 500: map@0.50 = 0.00106 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.78679
  > Step 751 (epoch 25): loss = 0.65045
val eval at step 1000: map@0.50 = 0.09046 - map@0.75 = 0.01377
  > Step 1001 (epoch 34): loss = 0.64953
  > Step 1251 (epoch 42): loss = 0.62228
val eval at step 1500: map@0.50 = 0.06520 - map@0.75 = 0.00413
  > Step 1501 (epoch 50): loss = 0.69410
  > Step 1751 (epoch 58): loss = 0.57857
val eval at step 2000: map@0.50 = 0.09231 - map@0.75 = 0.01309
  > Step 2001 (epoch 67): loss = 0.53109
  > Step 2251 (epoch 75): loss = 0.51748
val eval at step 2500: map@0.50 = 0.16021 - map@0.75 = 0.02890
  > Step 2501 (epoch 83): loss = 0.49700
  > Step 2751 (epoch 91): loss = 0.52910
val eval at step 3000: map@0.50 = 0.17354 - map@0.75 = 0.02422
  > Step 3001 (epoch 100): loss = 0.55513
  > Step 3251 (epoch 108): loss = 0.49642
val eval at step 3500: map@0.50 = 0.04483 - map@0.75 = 0.00964
  > Step 3501 (epoch 116): loss = 1.17917
  > Step 3751 (epoch 125): loss = 0.52591
val eval at step 4000: map@0.50 = 0.19385 - map@0.75 = 0.04011
  > Step 4001 (epoch 133): loss = 0.42332
  > Step 4251 (epoch 141): loss = 0.43382
val eval at step 4500: map@0.50 = 0.26579 - map@0.75 = 0.05536
  > Step 4501 (epoch 149): loss = 0.42519
  > Step 4751 (epoch 158): loss = 0.35493
val eval at step 5000: map@0.50 = 0.26706 - map@0.75 = 0.04770
  > Step 5001 (epoch 166): loss = 0.45867
  > Step 5251 (epoch 174): loss = 0.38651
val eval at step 5500: map@0.50 = 0.13592 - map@0.75 = 0.02673
  > Step 5501 (epoch 182): loss = 0.76967
  > Step 5751 (epoch 191): loss = 0.37545
val eval at step 6000: map@0.50 = 0.36066 - map@0.75 = 0.06041
  > Step 6001 (epoch 199): loss = 0.36614
  > Step 6251 (epoch 207): loss = 0.33604
val eval at step 6500: map@0.50 = 0.36013 - map@0.75 = 0.09361
  > Step 6501 (epoch 215): loss = 0.37600
  > Step 6751 (epoch 224): loss = 0.27887
val eval at step 7000: map@0.50 = 0.34621 - map@0.75 = 0.08343
  > Step 7001 (epoch 232): loss = 0.29717
  > Step 7251 (epoch 240): loss = 0.31147
val eval at step 7500: map@0.50 = 0.37781 - map@0.75 = 0.10576
  > Step 7501 (epoch 248): loss = 0.31994
  > Step 7751 (epoch 257): loss = 0.32741
val eval at step 8000: map@0.50 = 0.34825 - map@0.75 = 0.06302
  > Step 8001 (epoch 265): loss = 0.31222
  > Step 8251 (epoch 273): loss = 0.83434
val eval at step 8500: map@0.50 = 0.36225 - map@0.75 = 0.07140
  > Step 8501 (epoch 282): loss = 0.31483
  > Step 8751 (epoch 290): loss = 0.28704
val eval at step 9000: map@0.50 = 0.40166 - map@0.75 = 0.07377
  > Step 9001 (epoch 298): loss = 0.27278
  > Step 9251 (epoch 306): loss = 0.28702
val eval at step 9500: map@0.50 = 0.31294 - map@0.75 = 0.06755
  > Step 9501 (epoch 315): loss = 0.25274
  > Step 9751 (epoch 323): loss = 0.22804
val eval at step 10000: map@0.50 = 0.35293 - map@0.75 = 0.08527
  > Step 10001 (epoch 331): loss = 0.27610
  > Step 10251 (epoch 339): loss = 0.24677
val eval at step 10500: map@0.50 = 0.35904 - map@0.75 = 0.10621
  > Step 10501 (epoch 348): loss = 0.23387
  > Step 10751 (epoch 356): loss = 0.32301
val eval at step 11000: map@0.50 = 0.39513 - map@0.75 = 0.07607
  > Step 11001 (epoch 364): loss = 0.22031
  > Step 11251 (epoch 372): loss = 0.21626
val eval at step 11500: map@0.50 = 0.35624 - map@0.75 = 0.05553
  > Step 11501 (epoch 381): loss = 0.27791
  > Step 11751 (epoch 389): loss = 0.25695
val eval at step 12000: map@0.50 = 0.22755 - map@0.75 = 0.03151
  > Step 12001 (epoch 397): loss = 0.60064
  > Step 12251 (epoch 405): loss = 0.26273
val eval at step 12500: map@0.50 = 0.37185 - map@0.75 = 0.08769
  > Step 12501 (epoch 414): loss = 0.21820
  > Step 12751 (epoch 422): loss = 0.22883
val eval at step 13000: map@0.50 = 0.35929 - map@0.75 = 0.11405
  > Step 13001 (epoch 430): loss = 0.19402
  > Step 13251 (epoch 439): loss = 0.22210
val eval at step 13500: map@0.50 = 0.40390 - map@0.75 = 0.08001
  > Step 13501 (epoch 447): loss = 0.20467
  > Step 13751 (epoch 455): loss = 0.14204
val eval at step 14000: map@0.50 = 0.37941 - map@0.75 = 0.11212
  > Step 14001 (epoch 463): loss = 0.14579
  > Step 14251 (epoch 472): loss = 0.16098
val eval at step 14500: map@0.50 = 0.39970 - map@0.75 = 0.10615
  > Step 14501 (epoch 480): loss = 0.17761
  > Step 14751 (epoch 488): loss = 0.18199
val eval at step 15000: map@0.50 = 0.41442 - map@0.75 = 0.13153
  > Step 15001 (epoch 496): loss = 0.24590
  > Step 15251 (epoch 505): loss = 0.17397
val eval at step 15500: map@0.50 = 0.41352 - map@0.75 = 0.10785
  > Step 15501 (epoch 513): loss = 0.17812
  > Step 15751 (epoch 521): loss = 0.18485
val eval at step 16000: map@0.50 = 0.43725 - map@0.75 = 0.12166
  > Step 16001 (epoch 529): loss = 0.24456
  > Step 16251 (epoch 538): loss = 0.24188
val eval at step 16500: map@0.50 = 0.39158 - map@0.75 = 0.10263
  > Step 16501 (epoch 546): loss = 0.19611
  > Step 16751 (epoch 554): loss = 0.22781
val eval at step 17000: map@0.50 = 0.37532 - map@0.75 = 0.06334
  > Step 17001 (epoch 563): loss = 0.27666
  > Step 17251 (epoch 571): loss = 0.15488
val eval at step 17500: map@0.50 = 0.39299 - map@0.75 = 0.11151
  > Step 17501 (epoch 579): loss = 0.17834
  > Step 17751 (epoch 587): loss = 0.16035
val eval at step 18000: map@0.50 = 0.35183 - map@0.75 = 0.10275
  > Step 18001 (epoch 596): loss = 0.16636
test eval at step 18150: map@0.50 = 0.38066 - map@0.75 = 0.13726
Tensorflow version 1.10.1
ODGI - vedai_fold10, Input size 256

968 train samples (31 iters)
121 test samples (8 iters)

Config:
   [96mbatch_size:[0m 16
   [96mdata_classes:[0m ['camping car', 'car', 'others', 'pick-up', 'plane', 'ship', 'tractor', 'truck', 'van']
   [96mexp_name:[0m vedai_fold10
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/VEDAI/Vehicules1024/
   [96mimage_format:[0m vedai
   [96mlearning_rate:[0m 0.001
   [96mnetwork:[0m tiny-yolov2
   [96mnum_classes:[0m 9
   [96mnum_epochs:[0m 600
   [96mnum_gpus:[0m 2
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m vedai_fold10
   [96mtest_max_num_bbs:[0m 19
   [96mtest_num_iters_per_epoch:[0m 8
   [96mtest_num_samples:[0m 121
   [96mtest_num_samples_per_iter:[0m 16
   [96mtest_tfrecords:[0m Data/vedai_fold10_test
   [96mtrain_max_num_bbs:[0m 19
   [96mtrain_num_iters_per_epoch:[0m 31
   [96mtrain_num_samples:[0m 968
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/vedai_fold10_train
   [96mval_max_num_bbs:[0m 19
   [96mval_num_samples:[0m 121
   [96mval_tfrecords:[0m Data/vedai_fold10_val
   using grid size [8 8]
   using grid size [2 2]

Graph:
    with default `num_threads` = 8
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 2000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[None, 256, 256, 3], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[None, 8, 8, 1, 19], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[None], dtype=<dtype: 'int32'>
    [32mgroup_flags[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32mis_flipped[0m: shape=[None], dtype=<dtype: 'float32'>
 [31m> stage1[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    Output layer shape *(?, 8, 8, 1, 8)*
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    with default `train_num_crops` = 10
  > extracting 10 crops
    with default `target_conf_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
    [32m*confidence_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*offsets*[0m: shape=[None, 8, 8, 1, 2], dtype=<dtype: 'float32'>
    [32m*group_classification_logits*[0m: shape=[None, 8, 8, 1, 1], dtype=<dtype: 'float32'>
    [32m*crop_boxes*[0m: shape=[None, 10, 4], dtype=<dtype: 'float32'>
    [32m*crop_boxes_confidences*[0m: shape=[None, 10], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes_rescaled*[0m: shape=[None, 8, 8, 1, 4], dtype=<dtype: 'float32'>
 > create stage 2 inputs:
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 2000
    with default `num_threads` = 8
    *im_id*: shape=[None], dtype=<dtype: 'int32'>
    *image*: shape=[None, 64, 64, 3], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[None, 19, 4], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[None], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[None, 2, 2, 1, 19], dtype=<dtype: 'float32'>
 [31m> stage2[0m
    with default `weight_decay` = 0.0
    with default `normalizer_decay` = 0.9
    with default `with_classification` = False
    with default `with_group_flags` = False
    with default `with_offsets` = False
    Output layer shape *(?, 2, 2, 1, 5)*
    with default `target_conf_fn` = iou
    with default `assignment_reward_fn` = iou
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    [32m*confidence_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*detection_scores*[0m: shape=[None, 2, 2, 1, 1], dtype=<dtype: 'float32'>
    [32m*shifted_centers*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*log_scales*[0m: shape=[None, 2, 2, 1, 2], dtype=<dtype: 'float32'>
    [32m*bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    [32m*target_bounding_boxes*[0m: shape=[None, 2, 2, 1, 4], dtype=<dtype: 'float32'>
    with default `optimizer` = ADAM
 [31m> Build train operation[0m
    Using optimizer ADAM with learning rate 1.00e-03
    with default `beta1` = 0.9
    64 update operations found

Losses:
    *stage1_centers_localization_loss*: 2 tensors
    *stage1_scales_localization_loss*: 2 tensors
    *stage1_confidence_obj_loss*: 2 tensors
    *stage1_confidence_noobj_loss*: 2 tensors
    *stage1_group_classification_loss*: 2 tensors
    *stage1_classification_loss*: 2 tensors
    *stage1_offsets_loss*: 2 tensors
    *stage2_centers_localization_loss*: 2 tensors
    *stage2_scales_localization_loss*: 2 tensors
    *stage2_confidence_obj_loss*: 2 tensors
    *stage2_confidence_noobj_loss*: 2 tensors
    *stage2_classification_loss*: 2 tensors

total graph size: 0.99 MB
    with default `base_log_dir` = ./log
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/log/vedai_fold10/tiny-yolov2_odgi_256_64/09-25_06-12

Launch session:
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./log/vedai_fold10/tiny-yolov2_odgi_256_64/09-25_06-12[0m

Start training:
  > Step 1 (epoch 1): loss = 10.11204
  > Step 251 (epoch 9): loss = 1.21446
val eval at step 500: map@0.50 = 0.01860 - map@0.75 = 0.00000
  > Step 501 (epoch 17): loss = 0.84519
  > Step 751 (epoch 25): loss = 0.53574
val eval at step 1000: map@0.50 = 0.13970 - map@0.75 = 0.00275
  > Step 1001 (epoch 34): loss = 0.58194
  > Step 1251 (epoch 42): loss = 0.55941
val eval at step 1500: map@0.50 = 0.15072 - map@0.75 = 0.00217
  > Step 1501 (epoch 50): loss = 0.52577
  > Step 1751 (epoch 58): loss = 0.89067
val eval at step 2000: map@0.50 = 0.19503 - map@0.75 = 0.01240
  > Step 2001 (epoch 67): loss = 0.59104
  > Step 2251 (epoch 75): loss = 0.49166
val eval at step 2500: map@0.50 = 0.21044 - map@0.75 = 0.03563
  > Step 2501 (epoch 83): loss = 0.66366
  > Step 2751 (epoch 91): loss = 0.45559
val eval at step 3000: map@0.50 = 0.28629 - map@0.75 = 0.04374
  > Step 3001 (epoch 100): loss = 0.47159
  > Step 3251 (epoch 108): loss = 0.41136
val eval at step 3500: map@0.50 = 0.27434 - map@0.75 = 0.04406
  > Step 3501 (epoch 116): loss = 0.44705
  > Step 3751 (epoch 125): loss = 0.74020
val eval at step 4000: map@0.50 = 0.31916 - map@0.75 = 0.08267
  > Step 4001 (epoch 133): loss = 0.42797
  > Step 4251 (epoch 141): loss = 0.40998
val eval at step 4500: map@0.50 = 0.39853 - map@0.75 = 0.09600
  > Step 4501 (epoch 149): loss = 0.39564
  > Step 4751 (epoch 158): loss = 0.44863
val eval at step 5000: map@0.50 = 0.26243 - map@0.75 = 0.03848
  > Step 5001 (epoch 166): loss = 0.40813
  > Step 5251 (epoch 174): loss = 0.38068
val eval at step 5500: map@0.50 = 0.34589 - map@0.75 = 0.05923
  > Step 5501 (epoch 182): loss = 0.41183
  > Step 5751 (epoch 191): loss = 0.35178
val eval at step 6000: map@0.50 = 0.22465 - map@0.75 = 0.03740
  > Step 6001 (epoch 199): loss = 0.66974
  > Step 6251 (epoch 207): loss = 0.41616
val eval at step 6500: map@0.50 = 0.36888 - map@0.75 = 0.08381
  > Step 6501 (epoch 215): loss = 0.38004
  > Step 6751 (epoch 224): loss = 0.31563
val eval at step 7000: map@0.50 = 0.33534 - map@0.75 = 0.07782
  > Step 7001 (epoch 232): loss = 0.31448
  > Step 7251 (epoch 240): loss = 0.29445
val eval at step 7500: map@0.50 = 0.38996 - map@0.75 = 0.10331
  > Step 7501 (epoch 248): loss = 0.32817
  > Step 7751 (epoch 257): loss = 0.31867
val eval at step 8000: map@0.50 = 0.34763 - map@0.75 = 0.07796
  > Step 8001 (epoch 265): loss = 0.33909
  > Step 8251 (epoch 273): loss = 0.32086
val eval at step 8500: map@0.50 = 0.40673 - map@0.75 = 0.08243
  > Step 8501 (epoch 282): loss = 0.31687
  > Step 8751 (epoch 290): loss = 0.31165
val eval at step 9000: map@0.50 = 0.41472 - map@0.75 = 0.09827
  > Step 9001 (epoch 298): loss = 0.32458
  > Step 9251 (epoch 306): loss = 0.37819
val eval at step 9500: map@0.50 = 0.40985 - map@0.75 = 0.08289
  > Step 9501 (epoch 315): loss = 0.27180
  > Step 9751 (epoch 323): loss = 0.31806
val eval at step 10000: map@0.50 = 0.40382 - map@0.75 = 0.11013
  > Step 10001 (epoch 331): loss = 0.22553
  > Step 10251 (epoch 339): loss = 0.23022
val eval at step 10500: map@0.50 = 0.40054 - map@0.75 = 0.10144
  > Step 10501 (epoch 348): loss = 0.22096
  > Step 10751 (epoch 356): loss = 0.25827
val eval at step 11000: map@0.50 = 0.37920 - map@0.75 = 0.13451
  > Step 11001 (epoch 364): loss = 0.22143
  > Step 11251 (epoch 372): loss = 0.20719
val eval at step 11500: map@0.50 = 0.46175 - map@0.75 = 0.14354
  > Step 11501 (epoch 381): loss = 0.28085
  > Step 11751 (epoch 389): loss = 0.22018
val eval at step 12000: map@0.50 = 0.33880 - map@0.75 = 0.07223
  > Step 12001 (epoch 397): loss = 0.23056
  > Step 12251 (epoch 405): loss = 0.23772
val eval at step 12500: map@0.50 = 0.43564 - map@0.75 = 0.10938
  > Step 12501 (epoch 414): loss = 0.36748
  > Step 12751 (epoch 422): loss = 0.23887
val eval at step 13000: map@0.50 = 0.36620 - map@0.75 = 0.10006
  > Step 13001 (epoch 430): loss = 0.17633
  > Step 13251 (epoch 439): loss = 0.22042
val eval at step 13500: map@0.50 = 0.35772 - map@0.75 = 0.07964
  > Step 13501 (epoch 447): loss = 0.19303
  > Step 13751 (epoch 455): loss = 0.18452
val eval at step 14000: map@0.50 = 0.39179 - map@0.75 = 0.10110
  > Step 14001 (epoch 463): loss = 0.16645
  > Step 14251 (epoch 472): loss = 0.25207
val eval at step 14500: map@0.50 = 0.33714 - map@0.75 = 0.10923
  > Step 14501 (epoch 480): loss = 0.17207
  > Step 14751 (epoch 488): loss = 0.21019
val eval at step 15000: map@0.50 = 0.35615 - map@0.75 = 0.11307
  > Step 15001 (epoch 496): loss = 0.17312
  > Step 15251 (epoch 505): loss = 0.18043
val eval at step 15500: map@0.50 = 0.38849 - map@0.75 = 0.12066
  > Step 15501 (epoch 513): loss = 0.20710
  > Step 15751 (epoch 521): loss = 0.16075
val eval at step 16000: map@0.50 = 0.43119 - map@0.75 = 0.10603
  > Step 16001 (epoch 529): loss = 0.29665
  > Step 16251 (epoch 538): loss = 0.25290
val eval at step 16500: map@0.50 = 0.39776 - map@0.75 = 0.13271
  > Step 16501 (epoch 546): loss = 0.13688
  > Step 16751 (epoch 554): loss = 0.17760
val eval at step 17000: map@0.50 = 0.38915 - map@0.75 = 0.12418
  > Step 17001 (epoch 563): loss = 0.18560
  > Step 17251 (epoch 571): loss = 0.16966
val eval at step 17500: map@0.50 = 0.34427 - map@0.75 = 0.07446
  > Step 17501 (epoch 579): loss = 0.13789
  > Step 17751 (epoch 587): loss = 0.18209
val eval at step 18000: map@0.50 = 0.42152 - map@0.75 = 0.13878
  > Step 18001 (epoch 596): loss = 0.15095
test eval at step 18150: map@0.50 = 0.41783 - map@0.75 = 0.12463
