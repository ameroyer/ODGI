Tensorflow version 1.12.0
ODGI mobilenet_35 - mobilenet_35, Input size 512 - 128

9163 train samples (287 iters per epoch)
651 val samples (21 iters per epoch)
3281 test samples (103 iters per epoch)

Config:
   [96mbatch_size:[0m 8
   [96mdata_classes:[0m ['Biker', 'Bus', 'Car', 'Cart', 'Pedestrian', 'Skater']
   [96mexp_name:[0m sdd
   [96mfeature_keys:[0m ['im_id', 'num_boxes', 'bounding_boxes', 'classes']
   [96mgpu_mem_frac:[0m 1.0
   [96mimage_folder:[0m /nfs/scistore12/chlgrp/aroyer/Datasets/sdd_images/
   [96mimage_format:[0m sdd
   [96mlearning_rate:[0m 0.0002
   [96mnetwork:[0m mobilenet_35
   [96mnum_classes:[0m 6
   [96mnum_epochs:[0m 100
   [96mnum_gpus:[0m 4
   [96msave_evaluation_steps:[0m 500
   [96msave_summaries_steps:[0m None
   [96msetting:[0m sdd
   [96mtest_max_num_bbs:[0m 100
   [96mtest_num_crops:[0m 6
   [96mtest_num_iters_per_epoch:[0m 103
   [96mtest_num_samples:[0m 3281
   [96mtest_num_samples_per_iter:[0m 32
   [96mtest_patch_confidence_threshold:[0m 0.1
   [96mtest_patch_nms_threshold:[0m 0.25
   [96mtest_patch_strong_confidence_threshold:[0m 0.6
   [96mtest_tfrecords:[0m Data/sdd_test
   [96mtrain_max_num_bbs:[0m 100
   [96mtrain_num_crops:[0m 10
   [96mtrain_num_iters_per_epoch:[0m 287
   [96mtrain_num_samples:[0m 9163
   [96mtrain_num_samples_per_iter:[0m 32
   [96mtrain_tfrecords:[0m Data/sdd_train
   [96mval_max_num_bbs:[0m 100
   [96mval_num_iters_per_epoch:[0m 21
   [96mval_num_samples:[0m 651
   [96mval_num_samples_per_iter:[0m 32
   [96mval_tfrecords:[0m Data/sdd_val
    with default `base_log_dir` = ./run_logs
    Log directory /nfs/scistore12/chlgrp/aroyer/Jupyter/ODGI/run_logs/sdd/mobilenet_35_odgi_512_128/02-20_11-51
   using grid size [16 16]
   using grid size [4 4]

Train Graph:
    with default `num_threads` = 4
    with default `prefetch_capacity` = 1
    with default `with_classification` = False
    with default `shuffle_buffer` = 10000
    with default `data_augmentation_threshold` = 0.5
 [31m> load_inputs[0m
    [32mim_id[0m: shape=[8], dtype=<dtype: 'int32'>
    [32mbounding_boxes[0m: shape=[8, 100, 4], dtype=<dtype: 'float32'>
    [32mobj_i_mask_bbs[0m: shape=[8, 16, 16, 1, 100], dtype=<dtype: 'float32'>
    [32mnum_boxes[0m: shape=[8], dtype=<dtype: 'int32'>
    [32mis_flipped[0m: shape=[8], dtype=<dtype: 'float32'>
    [32mgroup_flags[0m: shape=[8, 16, 16, 1, 1], dtype=<dtype: 'float32'>
    [32mnum_group_boxes[0m: shape=[8], dtype=<dtype: 'int32'>
    [32mimage[0m: shape=[8, 512, 512, 3], dtype=<dtype: 'float32'>
    [32mgroup_bounding_boxes_per_cell[0m: shape=[8, 16, 16, 1, 4], dtype=<dtype: 'float32'>
 [33m> stage1/mobilenet_35[0m
    with default `with_classification` = False
    Output layer shape *(8, 16, 16, 1, 8)*
    [32mbounding_boxes[0m: shape=[8, 16, 16, 1, 4], dtype=<dtype: 'float32'>
    [32mgroup_classification_logits[0m: shape=[8, 16, 16, 1, 1], dtype=<dtype: 'float32'>
    [32mdetection_scores[0m: shape=[8, 16, 16, 1, 1], dtype=<dtype: 'float32'>
    [32mshifted_centers[0m: shape=[8, 16, 16, 1, 2], dtype=<dtype: 'float32'>
    [32moffsets[0m: shape=[8, 16, 16, 1, 2], dtype=<dtype: 'float32'>
    [32mlog_scales[0m: shape=[8, 16, 16, 1, 2], dtype=<dtype: 'float32'>
    [32mconfidence_scores[0m: shape=[8, 16, 16, 1, 1], dtype=<dtype: 'float32'>
 [33m> Collecting losses[0m
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
    with default `group_classification_loss_weight` = 1.0
    with default `offsets_loss_weight` = 1.0
    with default `offsets_margin` = 0.025
 [33m> Stage transition[0m
    with default `train_patch_confidence_threshold` = 0.0
    with default `train_patch_nms_threshold` = 1.0
    extracting 10 crops
    with default `patch_intersection_ratio_threshold` = 0.33
    with default `shuffle_buffer` = 10000
    with default `num_threads` = 4
    *im_id*: shape=[80], dtype=<dtype: 'int32'>
    *obj_i_mask_bbs*: shape=[80, 4, 4, 1, 100], dtype=<dtype: 'float32'>
    *bounding_boxes*: shape=[80, 100, 4], dtype=<dtype: 'float32'>
    *image*: shape=[80, 128, 128, 3], dtype=<dtype: 'float32'>
    *num_boxes*: shape=[80], dtype=<dtype: 'int32'>
 [33m> stage2/mobilenet_35[0m
    with default `num_boxes` = 1
    with default `with_classification` = False
    Output layer shape *(80, 4, 4, 1, 5)*
    [32mshifted_centers[0m: shape=[80, 4, 4, 1, 2], dtype=<dtype: 'float32'>
    [32mdetection_scores[0m: shape=[80, 4, 4, 1, 1], dtype=<dtype: 'float32'>
    [32mlog_scales[0m: shape=[80, 4, 4, 1, 2], dtype=<dtype: 'float32'>
    [32mbounding_boxes[0m: shape=[80, 4, 4, 1, 4], dtype=<dtype: 'float32'>
    [32mconfidence_scores[0m: shape=[80, 4, 4, 1, 1], dtype=<dtype: 'float32'>
 [33m> Collecting losses[0m
    with default `centers_localization_loss_weight` = 1.0
    with default `scales_localization_loss_weight` = 1.0
    with default `confidence_loss_weight` = 5.0
    with default `noobj_confidence_loss_weight` = 1.0
 [33m> Stage transition[0m
 [33m> Stage transition[0m
 [33m> Stage transition[0m

Losses:
 > [33min stage1 scope:[0m
     35 regularization losses found
     *stage1_group_classification_loss*: 4 tensors
     *stage1_offsets_loss*: 4 tensors
     *stage1_classification_loss*: 4 tensors
     *stage1_confidence_noobj_loss*: 4 tensors
     *stage1_confidence_obj_loss*: 4 tensors
     *stage1_scales_localization_loss*: 4 tensors
     *stage1_centers_localization_loss*: 4 tensors
     Trainable variables: [stage1/mobilenet_35/MobilenetV2/Conv/weights:0, stage1/mobilenet_35/MobilenetV2/Conv/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/Conv/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_1/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_2/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_3/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_4/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_5/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_6/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_7/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_8/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_9/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_10/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_11/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_12/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_13/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_14/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_15/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/expand/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/project/weights:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/expanded_conv_16/project/BatchNorm/beta:0, stage1/mobilenet_35/MobilenetV2/Conv_1/weights:0, stage1/mobilenet_35/MobilenetV2/Conv_1/BatchNorm/gamma:0, stage1/mobilenet_35/MobilenetV2/Conv_1/BatchNorm/beta:0, stage1/decode/fc_out/kernel:0, stage1/decode/fc_out/bias:0]
 > [33min stage2 scope:[0m
     35 regularization losses found
     *stage2_centers_localization_loss*: 4 tensors
     *stage2_scales_localization_loss*: 4 tensors
     *stage2_confidence_obj_loss*: 4 tensors
     *stage2_classification_loss*: 4 tensors
     *stage2_confidence_noobj_loss*: 4 tensors
     Trainable variables: [stage2/mobilenet_35/MobilenetV2/Conv/weights:0, stage2/mobilenet_35/MobilenetV2/Conv/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/Conv/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_1/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_2/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_3/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_4/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_5/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_6/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_7/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_8/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_9/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_10/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_11/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_12/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_13/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_14/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_15/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/expand/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/project/weights:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/expanded_conv_16/project/BatchNorm/beta:0, stage2/mobilenet_35/MobilenetV2/Conv_1/weights:0, stage2/mobilenet_35/MobilenetV2/Conv_1/BatchNorm/gamma:0, stage2/mobilenet_35/MobilenetV2/Conv_1/BatchNorm/beta:0, stage2/decode/fc_out/kernel:0, stage2/decode/fc_out/bias:0]
 [33m> Build train operation[0m
    with default `optimizer` = ADAM
    Using optimizer ADAM with learning rate 2.00e-04
    with default `beta1` = 0.9
    416 update operations found in stage1 scope
    416 update operations found in stage2 scope

total graph size: 20.73 MB
    with default `max_to_keep` = 1
    with default `save_checkpoint_steps` = 2000
    [31mWarning:[0m No summaries found in collection "outputs"
    [31mWarning:[0m No summaries found in collection "config"
    saving checkpoint in [36m./run_logs/sdd/mobilenet_35_odgi_512_128/02-20_11-51[0m

Start training:
[33m   Epoch 0: start training stage 2[0m
  > [00:01] Step 1 (epoch 1): loss 1 = 18.17936, loss 2 = 20.00004
  > [00:06] Step 251 (epoch 1): loss 1 = 1.14036, loss 2 = 0.83796
evaluated 635 val images at step 500: map@0.50 = 0.00547 - map@0.75 = 0.00003
  > [00:10] Step 501 (epoch 2): loss 1 = 1.14655, loss 2 = 0.67212
  > [00:14] Step 751 (epoch 3): loss 1 = 1.12802, loss 2 = 0.67060
evaluated 635 val images at step 1000: map@0.50 = 0.01098 - map@0.75 = 0.00055
  > [00:19] Step 1001 (epoch 4): loss 1 = 0.93497, loss 2 = 0.57782
  > [00:23] Step 1251 (epoch 5): loss 1 = 0.84248, loss 2 = 0.51829
evaluated 635 val images at step 1500: map@0.50 = 0.02979 - map@0.75 = 0.00168
  > [00:27] Step 1501 (epoch 6): loss 1 = 0.88371, loss 2 = 0.56377
  > [00:31] Step 1751 (epoch 7): loss 1 = 0.88830, loss 2 = 0.50456
evaluated 635 val images at step 2000: map@0.50 = 0.05425 - map@0.75 = 0.00321
  > [00:35] Step 2001 (epoch 7): loss 1 = 0.82932, loss 2 = 0.50831
  > [00:39] Step 2251 (epoch 8): loss 1 = 0.84568, loss 2 = 0.49350
evaluated 635 val images at step 2500: map@0.50 = 0.06946 - map@0.75 = 0.00440
  > [00:44] Step 2501 (epoch 9): loss 1 = 0.86069, loss 2 = 0.52175
  > [00:48] Step 2751 (epoch 10): loss 1 = 0.70739, loss 2 = 0.52343
evaluated 635 val images at step 3000: map@0.50 = 0.09529 - map@0.75 = 0.00462
  > [00:52] Step 3001 (epoch 11): loss 1 = 0.68461, loss 2 = 0.48163
  > [00:56] Step 3251 (epoch 12): loss 1 = 0.78251, loss 2 = 0.48757
evaluated 635 val images at step 3500: map@0.50 = 0.10816 - map@0.75 = 0.00743
  > [01:01] Step 3501 (epoch 13): loss 1 = 0.74770, loss 2 = 0.47275
  > [01:05] Step 3751 (epoch 14): loss 1 = 0.68888, loss 2 = 0.51046
evaluated 635 val images at step 4000: map@0.50 = 0.13528 - map@0.75 = 0.00904
  > [01:09] Step 4001 (epoch 14): loss 1 = 0.78262, loss 2 = 0.47143
  > [01:13] Step 4251 (epoch 15): loss 1 = 0.72147, loss 2 = 0.49098
evaluated 635 val images at step 4500: map@0.50 = 0.15432 - map@0.75 = 0.01550
  > [01:17] Step 4501 (epoch 16): loss 1 = 0.72964, loss 2 = 0.49224
  > [01:21] Step 4751 (epoch 17): loss 1 = 0.63009, loss 2 = 0.45749
evaluated 635 val images at step 5000: map@0.50 = 0.17161 - map@0.75 = 0.01399
  > [01:26] Step 5001 (epoch 18): loss 1 = 0.73835, loss 2 = 0.44291
  > [01:30] Step 5251 (epoch 19): loss 1 = 0.63298, loss 2 = 0.43924
evaluated 635 val images at step 5500: map@0.50 = 0.20330 - map@0.75 = 0.01810
  > [01:34] Step 5501 (epoch 20): loss 1 = 0.65886, loss 2 = 0.45046
  > [01:37] Step 5751 (epoch 21): loss 1 = 0.66246, loss 2 = 0.44239
evaluated 635 val images at step 6000: map@0.50 = 0.21499 - map@0.75 = 0.01897
  > [01:41] Step 6001 (epoch 21): loss 1 = 0.78025, loss 2 = 0.44815
  > [01:45] Step 6251 (epoch 22): loss 1 = 0.69398, loss 2 = 0.41867
evaluated 635 val images at step 6500: map@0.50 = 0.22536 - map@0.75 = 0.02032
  > [01:49] Step 6501 (epoch 23): loss 1 = 0.60386, loss 2 = 0.41534
  > [01:53] Step 6751 (epoch 24): loss 1 = 0.61699, loss 2 = 0.42619
evaluated 635 val images at step 7000: map@0.50 = 0.24556 - map@0.75 = 0.02188
  > [01:57] Step 7001 (epoch 25): loss 1 = 0.64256, loss 2 = 0.40827
  > [02:00] Step 7251 (epoch 26): loss 1 = 0.67764, loss 2 = 0.42194
evaluated 635 val images at step 7500: map@0.50 = 0.25284 - map@0.75 = 0.02345
  > [02:04] Step 7501 (epoch 27): loss 1 = 0.61473, loss 2 = 0.41597
  > [02:08] Step 7751 (epoch 28): loss 1 = 0.61829, loss 2 = 0.36483
evaluated 635 val images at step 8000: map@0.50 = 0.24898 - map@0.75 = 0.03087
  > [02:12] Step 8001 (epoch 28): loss 1 = 0.70398, loss 2 = 0.40584
  > [02:16] Step 8251 (epoch 29): loss 1 = 0.69898, loss 2 = 0.44214
evaluated 635 val images at step 8500: map@0.50 = 0.27172 - map@0.75 = 0.02837
  > [02:20] Step 8501 (epoch 30): loss 1 = 0.53102, loss 2 = 0.41403
  > [02:24] Step 8751 (epoch 31): loss 1 = 0.59701, loss 2 = 0.40399
evaluated 635 val images at step 9000: map@0.50 = 0.28530 - map@0.75 = 0.02931
  > [02:28] Step 9001 (epoch 32): loss 1 = 0.57075, loss 2 = 0.42354
  > [02:31] Step 9251 (epoch 33): loss 1 = 0.53246, loss 2 = 0.40358
evaluated 635 val images at step 9500: map@0.50 = 0.28297 - map@0.75 = 0.02866
  > [02:35] Step 9501 (epoch 34): loss 1 = 0.54957, loss 2 = 0.39341
  > [02:39] Step 9751 (epoch 35): loss 1 = 0.60265, loss 2 = 0.38365
evaluated 635 val images at step 10000: map@0.50 = 0.27659 - map@0.75 = 0.02837
  > [02:43] Step 10001 (epoch 35): loss 1 = 0.66299, loss 2 = 0.40836
  > [02:47] Step 10251 (epoch 36): loss 1 = 0.57182, loss 2 = 0.38302
evaluated 635 val images at step 10500: map@0.50 = 0.30283 - map@0.75 = 0.03501
  > [02:51] Step 10501 (epoch 37): loss 1 = 0.54516, loss 2 = 0.38379
  > [02:54] Step 10751 (epoch 38): loss 1 = 0.55352, loss 2 = 0.40154
evaluated 635 val images at step 11000: map@0.50 = 0.29989 - map@0.75 = 0.03853
  > [02:58] Step 11001 (epoch 39): loss 1 = 0.51049, loss 2 = 0.38379
  > [03:02] Step 11251 (epoch 40): loss 1 = 0.55203, loss 2 = 0.39258
evaluated 635 val images at step 11500: map@0.50 = 0.30884 - map@0.75 = 0.03483
  > [03:06] Step 11501 (epoch 41): loss 1 = 0.53531, loss 2 = 0.35387
  > [03:10] Step 11751 (epoch 42): loss 1 = 0.51720, loss 2 = 0.38989
evaluated 635 val images at step 12000: map@0.50 = 0.30095 - map@0.75 = 0.03714
  > [03:14] Step 12001 (epoch 42): loss 1 = 0.58075, loss 2 = 0.39965
  > [03:18] Step 12251 (epoch 43): loss 1 = 0.58084, loss 2 = 0.34884
evaluated 635 val images at step 12500: map@0.50 = 0.31395 - map@0.75 = 0.03445
  > [03:22] Step 12501 (epoch 44): loss 1 = 0.52069, loss 2 = 0.39820
  > [03:26] Step 12751 (epoch 45): loss 1 = 0.51355, loss 2 = 0.38834
evaluated 635 val images at step 13000: map@0.50 = 0.30537 - map@0.75 = 0.03675
  > [03:30] Step 13001 (epoch 46): loss 1 = 0.51806, loss 2 = 0.36037
  > [03:34] Step 13251 (epoch 47): loss 1 = 0.49732, loss 2 = 0.37795
evaluated 635 val images at step 13500: map@0.50 = 0.32179 - map@0.75 = 0.03814
  > [03:39] Step 13501 (epoch 48): loss 1 = 0.53433, loss 2 = 0.38519
  > [03:43] Step 13751 (epoch 49): loss 1 = 0.50556, loss 2 = 0.34798
evaluated 635 val images at step 14000: map@0.50 = 0.31420 - map@0.75 = 0.03597
  > [03:47] Step 14001 (epoch 49): loss 1 = 0.55241, loss 2 = 0.37190
  > [03:51] Step 14251 (epoch 50): loss 1 = 0.57857, loss 2 = 0.38696
evaluated 635 val images at step 14500: map@0.50 = 0.31337 - map@0.75 = 0.03363
  > [03:56] Step 14501 (epoch 51): loss 1 = 0.44202, loss 2 = 0.38510
  > [04:00] Step 14751 (epoch 52): loss 1 = 0.57710, loss 2 = 0.35239
evaluated 635 val images at step 15000: map@0.50 = 0.32230 - map@0.75 = 0.03967
  > [04:04] Step 15001 (epoch 53): loss 1 = 0.43341, loss 2 = 0.37191
  > [04:08] Step 15251 (epoch 54): loss 1 = 0.58041, loss 2 = 0.36496
evaluated 635 val images at step 15500: map@0.50 = 0.31767 - map@0.75 = 0.03901
  > [04:13] Step 15501 (epoch 55): loss 1 = 0.46139, loss 2 = 0.36819
  > [04:17] Step 15751 (epoch 56): loss 1 = 0.50800, loss 2 = 0.35482
evaluated 635 val images at step 16000: map@0.50 = 0.33150 - map@0.75 = 0.03674
  > [04:21] Step 16001 (epoch 56): loss 1 = 0.47410, loss 2 = 0.32070
  > [04:25] Step 16251 (epoch 57): loss 1 = 0.47532, loss 2 = 0.38482
evaluated 635 val images at step 16500: map@0.50 = 0.30970 - map@0.75 = 0.03371
  > [04:30] Step 16501 (epoch 58): loss 1 = 0.53870, loss 2 = 0.35672
  > [04:34] Step 16751 (epoch 59): loss 1 = 0.47931, loss 2 = 0.31122
evaluated 635 val images at step 17000: map@0.50 = 0.32702 - map@0.75 = 0.03509
  > [04:38] Step 17001 (epoch 60): loss 1 = 0.48823, loss 2 = 0.35621
  > [04:42] Step 17251 (epoch 61): loss 1 = 0.50515, loss 2 = 0.36196
evaluated 635 val images at step 17500: map@0.50 = 0.32355 - map@0.75 = 0.03884
  > [04:46] Step 17501 (epoch 62): loss 1 = 0.54588, loss 2 = 0.35906
  > [04:50] Step 17751 (epoch 62): loss 1 = 0.62692, loss 2 = 0.37685
evaluated 635 val images at step 18000: map@0.50 = 0.33137 - map@0.75 = 0.03555
  > [04:55] Step 18001 (epoch 63): loss 1 = 0.43870, loss 2 = 0.36810
  > [04:59] Step 18251 (epoch 64): loss 1 = 0.51312, loss 2 = 0.36958
evaluated 635 val images at step 18500: map@0.50 = 0.32886 - map@0.75 = 0.03658
  > [05:03] Step 18501 (epoch 65): loss 1 = 0.48007, loss 2 = 0.36402
  > [05:07] Step 18751 (epoch 66): loss 1 = 0.45839, loss 2 = 0.37149
evaluated 635 val images at step 19000: map@0.50 = 0.31326 - map@0.75 = 0.03686
  > [05:12] Step 19001 (epoch 67): loss 1 = 0.39790, loss 2 = 0.34515
  > [05:16] Step 19251 (epoch 68): loss 1 = 0.46213, loss 2 = 0.35565
evaluated 635 val images at step 19500: map@0.50 = 0.31827 - map@0.75 = 0.03938
  > [05:20] Step 19501 (epoch 69): loss 1 = 0.42338, loss 2 = 0.31993
  > [05:24] Step 19751 (epoch 69): loss 1 = 0.43323, loss 2 = 0.35487
evaluated 635 val images at step 20000: map@0.50 = 0.32731 - map@0.75 = 0.03767
  > [05:29] Step 20001 (epoch 70): loss 1 = 0.43046, loss 2 = 0.35317
  > [05:33] Step 20251 (epoch 71): loss 1 = 0.44500, loss 2 = 0.34015
evaluated 635 val images at step 20500: map@0.50 = 0.32867 - map@0.75 = 0.04186
  > [05:37] Step 20501 (epoch 72): loss 1 = 0.54701, loss 2 = 0.35689
  > [05:41] Step 20751 (epoch 73): loss 1 = 0.46108, loss 2 = 0.37672
evaluated 635 val images at step 21000: map@0.50 = 0.32917 - map@0.75 = 0.03899
  > [05:45] Step 21001 (epoch 74): loss 1 = 0.48139, loss 2 = 0.35037
  > [05:50] Step 21251 (epoch 75): loss 1 = 0.44905, loss 2 = 0.32232
evaluated 635 val images at step 21500: map@0.50 = 0.33404 - map@0.75 = 0.03711
  > [05:54] Step 21501 (epoch 76): loss 1 = 0.40647, loss 2 = 0.34510
  > [05:58] Step 21751 (epoch 76): loss 1 = 0.46326, loss 2 = 0.36785
evaluated 635 val images at step 22000: map@0.50 = 0.33399 - map@0.75 = 0.03653
  > [06:02] Step 22001 (epoch 77): loss 1 = 0.44263, loss 2 = 0.35266
  > [06:07] Step 22251 (epoch 78): loss 1 = 0.41932, loss 2 = 0.35091
evaluated 635 val images at step 22500: map@0.50 = 0.33550 - map@0.75 = 0.04102
  > [06:11] Step 22501 (epoch 79): loss 1 = 0.40906, loss 2 = 0.36698
  > [06:15] Step 22751 (epoch 80): loss 1 = 0.42944, loss 2 = 0.35743
evaluated 635 val images at step 23000: map@0.50 = 0.33244 - map@0.75 = 0.03722
  > [06:19] Step 23001 (epoch 81): loss 1 = 0.40581, loss 2 = 0.32305
  > [06:23] Step 23251 (epoch 82): loss 1 = 0.40940, loss 2 = 0.33034
evaluated 635 val images at step 23500: map@0.50 = 0.32653 - map@0.75 = 0.04121
  > [06:28] Step 23501 (epoch 83): loss 1 = 0.45327, loss 2 = 0.37439
  > [06:32] Step 23751 (epoch 83): loss 1 = 0.42463, loss 2 = 0.35466
evaluated 635 val images at step 24000: map@0.50 = 0.32960 - map@0.75 = 0.04239
  > [06:36] Step 24001 (epoch 84): loss 1 = 0.39757, loss 2 = 0.33298
  > [06:40] Step 24251 (epoch 85): loss 1 = 0.49519, loss 2 = 0.39090
evaluated 635 val images at step 24500: map@0.50 = 0.32305 - map@0.75 = 0.03612
  > [06:45] Step 24501 (epoch 86): loss 1 = 0.47324, loss 2 = 0.34969
  > [06:49] Step 24751 (epoch 87): loss 1 = 0.40086, loss 2 = 0.30820
evaluated 635 val images at step 25000: map@0.50 = 0.33885 - map@0.75 = 0.04588
  > [06:53] Step 25001 (epoch 88): loss 1 = 0.45985, loss 2 = 0.35256
  > [06:57] Step 25251 (epoch 89): loss 1 = 0.46389, loss 2 = 0.35377
evaluated 635 val images at step 25500: map@0.50 = 0.31523 - map@0.75 = 0.03940
  > [07:02] Step 25501 (epoch 90): loss 1 = 0.43346, loss 2 = 0.33362
  > [07:06] Step 25751 (epoch 90): loss 1 = 0.42752, loss 2 = 0.37509
evaluated 635 val images at step 26000: map@0.50 = 0.33233 - map@0.75 = 0.03544
  > [07:10] Step 26001 (epoch 91): loss 1 = 0.41133, loss 2 = 0.37167
  > [07:14] Step 26251 (epoch 92): loss 1 = 0.41989, loss 2 = 0.34462
evaluated 635 val images at step 26500: map@0.50 = 0.32284 - map@0.75 = 0.04131
  > [07:19] Step 26501 (epoch 93): loss 1 = 0.42570, loss 2 = 0.35143
  > [07:23] Step 26751 (epoch 94): loss 1 = 0.38441, loss 2 = 0.35870
evaluated 635 val images at step 27000: map@0.50 = 0.33796 - map@0.75 = 0.04000
  > [07:27] Step 27001 (epoch 95): loss 1 = 0.40473, loss 2 = 0.33232
  > [07:31] Step 27251 (epoch 96): loss 1 = 0.41411, loss 2 = 0.36270
evaluated 635 val images at step 27500: map@0.50 = 0.33504 - map@0.75 = 0.04343
  > [07:35] Step 27501 (epoch 97): loss 1 = 0.43834, loss 2 = 0.35654
  > [07:39] Step 27751 (epoch 97): loss 1 = 0.48664, loss 2 = 0.34671
evaluated 635 val images at step 28000: map@0.50 = 0.31054 - map@0.75 = 0.03263
  > [07:44] Step 28001 (epoch 98): loss 1 = 0.42518, loss 2 = 0.33018
  > [07:48] Step 28251 (epoch 99): loss 1 = 0.38908, loss 2 = 0.38247
evaluated 635 val images at step 28500: map@0.50 = 0.33659 - map@0.75 = 0.04476
  > [07:52] Step 28501 (epoch 100): loss 1 = 0.38773, loss 2 = 0.33587
evaluated 635 val images at step 28634: map@0.50 = 0.33034 - map@0.75 = 0.04517
evaluated 3199 test images at step 28634: map@0.50 = 0.33172 - map@0.75 = 0.04153
