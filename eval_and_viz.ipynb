{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version\", tf.__version__)\n",
    "\n",
    "from include import configuration\n",
    "from include import eval_utils\n",
    "from include import graph_manager\n",
    "from include import nets\n",
    "from include import viz\n",
    "from include import utils\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image, bbs, color=(1.0, 0.0, 0.0)):\n",
    "    \"\"\"Draw bounding boxes on the current image in Tensorflow with the specified color.\n",
    "    \n",
    "    Args:\n",
    "        image: A Tensor of shape (batch, size, size, 3).\n",
    "        bbs: A Tensor of shape (batch, n_boxes, 4) where the last axis is ordered as (xmin, ymin, xmax, ymax).\n",
    "    \"\"\"\n",
    "    r = len(bbs.get_shape())\n",
    "    assert r >= 3\n",
    "    if r > 3:        \n",
    "        bbs = utils.flatten_percell_output(bbs)\n",
    "    mask = - tf.ones(tf.shape(image))\n",
    "    mask = tf.image.draw_bounding_boxes(mask, tf.gather(bbs, [1, 0, 3, 2], axis=-1))\n",
    "    mask = tf.clip_by_value(mask, -1., 0.) +1. # 0. if nothing, 1. on box position\n",
    "    return (1. - mask) * image + mask * color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard detector \n",
    "\n",
    "Returns the final mean average precision on the test set and a few vizualisations of the output boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_standard(log_dir, \n",
    "                      batch_size=16,\n",
    "                      viz_confidence_threshold=0.25,\n",
    "                      viz_confidence_threshold_2=0.5,\n",
    "                      retrieval_nms_threshold=0.5,\n",
    "                      retrieval_confidence_threshold=0.,\n",
    "                      retrieval_iou_threshold=[0.5, 0.75],\n",
    "                      output=True,\n",
    "                      display=True,\n",
    "                      verbose=0):\n",
    "    ## Configuration\n",
    "    with open(os.path.join(log_dir, 'config.pkl'), 'rb') as f:\n",
    "        config = pickle.load(f)\n",
    "    config['batch_size'] = batch_size\n",
    "    config['nms_threshold'] = retrieval_nms_threshold\n",
    "    config['retrieval_confidence_threshold'] = retrieval_confidence_threshold\n",
    "    config['retrieval_iou_threshold'] = retrieval_iou_threshold \n",
    "    config['num_gpus'] = 1\n",
    "    config['shuffle_test'] = True\n",
    "    \n",
    "    ############## Graph\n",
    "    with tf.Graph().as_default():\n",
    "        ## Inputs\n",
    "        eval_split_placehoder = tf.placeholder_with_default(True, (), 'choose_eval_split')\n",
    "        eval_inputs, eval_initializer = tf.cond(\n",
    "            eval_split_placehoder,\n",
    "            true_fn=lambda: graph_manager.get_inputs(mode='test', verbose=verbose, **config),\n",
    "            false_fn=lambda: graph_manager.get_inputs(mode='val', verbose=verbose, **config),\n",
    "            name='eval_inputs')\n",
    "        eval_inputs = eval_inputs[0]\n",
    "\n",
    "        ## Feed-forward\n",
    "        network = configuration.get_defaults(config, ['network'], verbose=True)[0]\n",
    "        forward_fn = tf.make_template(network, getattr(nets, network))\n",
    "        decode_fn = tf.make_template('decode', nets.get_detection_outputs)\n",
    "        forward_pass = partial(nets.forward, forward_fn=forward_fn, decode_fn=decode_fn)\n",
    "        eval_outputs = forward_pass(eval_inputs['image'], config, is_training=False, verbose=verbose)\n",
    "\n",
    "        ## Draw bounding boxes\n",
    "        gt_boxes = draw_bounding_boxes(\n",
    "            eval_inputs['image'], eval_inputs['bounding_boxes'], color=(0., 1., 0.))\n",
    "        filtered_boxes = eval_outputs['bounding_boxes'] * tf.to_float(\n",
    "            eval_outputs['confidence_scores'] > viz_confidence_threshold)\n",
    "        filtered_boxes_1 =  draw_bounding_boxes(eval_inputs['image'], filtered_boxes, color=(1., 1., 0.))\n",
    "        filtered_boxes = eval_outputs['bounding_boxes'] * tf.to_float(\n",
    "            eval_outputs['confidence_scores'] > viz_confidence_threshold_2)\n",
    "        filtered_boxes_2 =  draw_bounding_boxes(eval_inputs['image'], filtered_boxes, color=(1., 0., 1.))\n",
    "        images = tf.stack([gt_boxes, filtered_boxes_1, filtered_boxes_2], axis=1)\n",
    "\n",
    "        ## Evaluation\n",
    "        eval_outputs = [eval_inputs['im_id'], eval_inputs['num_boxes'], eval_inputs['bounding_boxes'],\n",
    "                        eval_outputs['bounding_boxes'], eval_outputs['detection_scores']]\n",
    "        test_results_path = os.path.join(config[\"log_dir\"], 'test_output.txt')\n",
    "        eval_test = partial(graph_manager.run_eval, \n",
    "                            eval_split_placehoder=eval_split_placehoder,\n",
    "                            eval_initializer=eval_initializer, \n",
    "                            eval_outputs=eval_outputs,\n",
    "                            configuration=config,\n",
    "                            mode='test',\n",
    "                            results_path=test_results_path)\n",
    "\n",
    "\n",
    "        ############## Session\n",
    "        session_creator = tf.train.ChiefSessionCreator(\n",
    "            checkpoint_dir=log_dir, config=tf.ConfigProto(allow_soft_placement=True))\n",
    "\n",
    "        # Start session\n",
    "        with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "            # evaluate\n",
    "            mean_aps, _, _ = eval_test(sess, 0)\n",
    "            print('Mean AP', np.mean(mean_aps))\n",
    "\n",
    "            # viz\n",
    "            if output or display:\n",
    "                sess.run(eval_initializer)\n",
    "                im_ids_, images_ = sess.run([eval_inputs['im_id'], images])                                    \n",
    "                fig, axis = plt.subplots(batch_size, 3, figsize=(15, 5 * batch_size))\n",
    "                for i, (im_id, image) in enumerate(zip(im_ids_, images_)):\n",
    "                    axis[i][0].set_title('Ground-truth (%s)' % im_id)\n",
    "                    axis[i][1].set_title('Predicted boxes (c > %.2f)' % viz_confidence_threshold)\n",
    "                    axis[i][2].set_title('Predicted boxes (c > %.2f)' % viz_confidence_threshold_2)\n",
    "                    for j in range(3):\n",
    "                        axis[i][j].imshow(image[j])\n",
    "                        axis[i][j].set_axis_off()\n",
    "                fig.tight_layout()\n",
    "                if output:\n",
    "                    plt.savefig(os.path.join(config['log_dir'], 'prediction_example.png'), dpi=150)\n",
    "                if not display:\n",
    "                    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.41486 - map@0.75 = 0.06062\n",
      "CPU times: user 14min 42s, sys: 1min 12s, total: 15min 54s\n",
      "Wall time: 7min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_standard('run_logs/sdd/mobilenet_100_standard_1024/02-19_13-08/', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.26573 - map@0.75 = 0.02752\n"
     ]
    }
   ],
   "source": [
    "evaluate_standard('run_logs/sdd/mobilenet_100_standard_512/02-19_08-59/', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.10016 - map@0.75 = 0.00857\n"
     ]
    }
   ],
   "source": [
    "evaluate_standard('run_logs/sdd/mobilenet_100_standard_256/02-19_16-44/', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 4952 test images at step 0: map@0.50 = 0.39795 - map@0.55 = 0.35457 - map@0.60 = 0.30792 - map@0.65 = 0.25368 - map@0.70 = 0.19561 - map@0.75 = 0.13621 - map@0.80 = 0.08831 - map@0.85 = 0.04136 - map@0.90 = 0.01374 - map@0.95 = 0.00129\n",
      "Mean AP 0.179064434102631\n",
      "CPU times: user 4min 16s, sys: 47.8 s, total: 5min 4s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_standard('run_logs/mscoco/mobilenet_100_standard_416/02-21_17-00/', display=False,\n",
    "                  retrieval_iou_threshold=[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODGI detector\n",
    "Returns the final mean average precision on the test set, a few vizualisations of the output boxes, and an analysis of patch occupancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "from train_odgi import stage_transition, format_final_boxes\n",
    "\n",
    "def evaluate_odgi(log_dir, \n",
    "                  batch_size=16,\n",
    "                  test_num_crops=6,\n",
    "                  test_patch_nms_threshold=0.25,\n",
    "                  test_patch_confidence_threshold=0.1,\n",
    "                  test_patch_strong_confidence_threshold=0.6,\n",
    "                  viz_confidence_threshold=0.25,\n",
    "                  viz_confidence_threshold_2=0.25,\n",
    "                  retrieval_nms_threshold=0.5,\n",
    "                  retrieval_confidence_threshold=0.,\n",
    "                  retrieval_iou_threshold=[0.5, 0.75],\n",
    "                  occupancy_threshold=0.25,\n",
    "                  display_with_nms=False,\n",
    "                  output=True,\n",
    "                  display=True,\n",
    "                  share_variables=False,\n",
    "                  verbose=0):\n",
    "    ## Configuration\n",
    "    stages = []\n",
    "    for i, base_name in enumerate(['stage1', 'stage2']):\n",
    "        ## Config\n",
    "        with open(os.path.join(log_dir, '%s_config.pkl' % base_name), 'rb') as f:\n",
    "            config = pickle.load(f)\n",
    "        config['nms_threshold'] = retrieval_nms_threshold\n",
    "        config['retrieval_confidence_threshold'] = retrieval_confidence_threshold\n",
    "        config['retrieval_iou_threshold'] = retrieval_iou_threshold \n",
    "        config['num_gpus'] = 1\n",
    "        config['shuffle_test'] = True\n",
    "        config['test_num_crops'] = test_num_crops\n",
    "        config['test_patch_nms_threshold'] = test_patch_nms_threshold\n",
    "        config['test_patch_confidence_threshold'] = test_patch_confidence_threshold\n",
    "        config['test_patch_strong_confidence_threshold'] = test_patch_strong_confidence_threshold\n",
    "        ## Templates\n",
    "        if not share_variables:\n",
    "            network_name = configuration.get_defaults(config, ['network'], verbose=True)[0]\n",
    "            forward_fn = tf.make_template('%s/%s' % (base_name, network_name), getattr(nets, network_name)) \n",
    "        elif i == 0:\n",
    "            network_name = configuration.get_defaults(config, ['network'], verbose=True)[0]\n",
    "            forward_fn = tf.make_template(network_name, getattr(nets, network_name)) \n",
    "        if i == 0:\n",
    "            decode_fn = tf.make_template('%s/decode' % base_name, nets.get_detection_outputs_with_groups)\n",
    "        else:\n",
    "            decode_fn = tf.make_template('%s/decode' % base_name, nets.get_detection_outputs)\n",
    "        forward_pass = partial(nets.forward, forward_fn=forward_fn, decode_fn=decode_fn)\n",
    "        stages.append((base_name, network_name, forward_pass, config))\n",
    "    \n",
    "    stages[0][-1]['batch_size'] = batch_size\n",
    "    stages[1][-1]['previous_batch_size'] = batch_size\n",
    "    \n",
    "    ############## Graph\n",
    "    with tf.Graph().as_default():\n",
    "        ## Inputs\n",
    "        eval_split_placehoder = tf.placeholder_with_default(True, (), 'choose_eval_split')                  \n",
    "        eval_inputs, eval_initializer = tf.cond(\n",
    "            eval_split_placehoder,\n",
    "            true_fn=lambda: graph_manager.get_inputs(mode='test', verbose=0, **stages[0][3]),\n",
    "            false_fn=lambda: graph_manager.get_inputs(mode='val', verbose=0, **stages[0][3]),\n",
    "            name='eval_inputs')\n",
    "        eval_inputs = eval_inputs[0]\n",
    "\n",
    "        ## Feed-forward\n",
    "        stage_inputs = eval_inputs\n",
    "        image_ids = stage_inputs['im_id']\n",
    "        num_boxes = stage_inputs['num_boxes']\n",
    "        gt_bbs = stage_inputs['bounding_boxes']\n",
    "\n",
    "        for s, (name, _, forward_pass, stage_config) in enumerate(stages):                    \n",
    "            if s > 0:\n",
    "                stage_inputs = stage_transition(\n",
    "                    stage_inputs, stage_outputs, 'test', stage_config, verbose=0)\n",
    "            # stage 1\n",
    "            if s == 1:\n",
    "                stage1_pred_bbs = stage_outputs['bounding_boxes']\n",
    "                stage1_pred_confidences = stage_outputs['detection_scores']\n",
    "                stage1_kept_out_boxes = stage_outputs['kept_out_filter']\n",
    "                crop_boxes = stage_outputs['crop_boxes']\n",
    "                group_flags = stage_outputs['group_classification_logits']\n",
    "                \n",
    "            stage_outputs = forward_pass(\n",
    "                stage_inputs['image'], stage_config, is_training=False, verbose=0)\n",
    "\n",
    "            # stage 2 (final)\n",
    "            if s == 1:                    \n",
    "                stage_outputs = format_final_boxes(stage_outputs, crop_boxes)\n",
    "                stage2_pred_bbs = stage_outputs['bounding_boxes']\n",
    "                stage2_pred_confidences = stage_outputs['detection_scores']\n",
    "                \n",
    "        ## Evaluation\n",
    "        eval_outputs = [image_ids, num_boxes, gt_bbs, stage2_pred_bbs, stage2_pred_confidences,\n",
    "                        stage1_pred_bbs, stage1_pred_confidences, stage1_kept_out_boxes]  \n",
    "        test_results_path = os.path.join(config[\"log_dir\"], 'test_output.txt')\n",
    "        eval_test = partial(graph_manager.run_eval, \n",
    "                            eval_split_placehoder=eval_split_placehoder,\n",
    "                            eval_initializer=eval_initializer, \n",
    "                            eval_outputs=eval_outputs,\n",
    "                            configuration=config,\n",
    "                            mode='test',\n",
    "                            results_path=test_results_path)\n",
    "        \n",
    "        # Occupancy rate\n",
    "        # intersection between groupd-truth bounding boxes and crops\n",
    "        inters = utils.get_intersection_ratio(                                       \n",
    "            tf.split(tf.transpose(eval_inputs['bounding_boxes'], (0, 2, 1)), 4, axis=1), \n",
    "            tf.split(crop_boxes, 4, axis=-1))\n",
    "        # is_non_empty: How many ground-truth boxes are \"usefully\" present in each crop \n",
    "        occupied_filter = tf.to_float(inters > occupancy_threshold)\n",
    "        is_non_empty = tf.reduce_sum(occupied_filter, axis=-1)\n",
    "        # average over the number of crops\n",
    "        occupancy_rate = tf.reduce_sum(tf.to_float(is_non_empty > 0), axis=1)\n",
    "        occupancy_rate = tf.reduce_sum(occupancy_rate)\n",
    "        # coverage: how many of the ground-truth bbs are actually covered\n",
    "        coverage = tf.to_float(tf.reduce_sum(occupied_filter, axis=1) > 0)\n",
    "        coverage = tf.reduce_sum(coverage, axis=1)\n",
    "        coverage = coverage / (tf.to_float(eval_inputs['num_boxes']) + 1e-8)\n",
    "        coverage = tf.reduce_sum(coverage)\n",
    "        num_samples = tf.shape(inters)[0]\n",
    "        num_nonempty_samples = tf.reduce_sum(tf.to_float(eval_inputs['num_boxes'] > 0))\n",
    "\n",
    "        ## Draw bounding boxes\n",
    "        #ground-truth\n",
    "        gt_boxes = draw_bounding_boxes(\n",
    "            eval_inputs['image'], eval_inputs['bounding_boxes'], color=(0., 1., 0.))        \n",
    "        #predicted groups\n",
    "        stage1_filter = tf.to_float(stage1_pred_confidences > viz_confidence_threshold)\n",
    "        group_flags = tf.to_float(tf.nn.sigmoid(group_flags) >= 0.5)\n",
    "        group_bbs = stage1_pred_bbs * group_flags * stage1_filter\n",
    "        # non maximum suppression\n",
    "        if display_with_nms:\n",
    "            group_bbs = utils.flatten_percell_output(group_bbs)\n",
    "            stage1_pred_confidences = utils.flatten_percell_output(stage1_pred_confidences)\n",
    "            filtered_group_bbs = []\n",
    "            max_output_size = tf.shape(group_bbs)[1]\n",
    "            for i in range(batch_size):\n",
    "                filtered_group_bbs.append(utils.nms_with_pad(\n",
    "                        group_bbs[i], stage1_pred_confidences[i, :, 0], max_output_size)[0])\n",
    "            group_bbs = tf.stack(filtered_group_bbs, axis=0)\n",
    "        groups = draw_bounding_boxes(eval_inputs['image'], group_bbs, color=(1., 0., 1.))\n",
    "        # Short-cut individuals\n",
    "        individuals = utils.flatten_percell_output((1. - group_flags) * stage1_filter * stage1_pred_bbs)\n",
    "        shortcut_individuals = tf.expand_dims(stage1_kept_out_boxes, axis=-1) * individuals\n",
    "        shortcut_boxes = draw_bounding_boxes(\n",
    "            eval_inputs['image'], individuals, color=(0., 0., 1.))\n",
    "        shortcut_boxes = draw_bounding_boxes(\n",
    "            shortcut_boxes, shortcut_individuals, color=(0., 1., 1.))\n",
    "        # Crops (after offsets)\n",
    "        crops = draw_bounding_boxes(eval_inputs['image'], crop_boxes, color=(1., 1., 1.))\n",
    "        # outputs from stage 2\n",
    "        stage2_pred_bbs *= tf.to_float(stage2_pred_confidences > viz_confidence_threshold_2)\n",
    "        stage2_boxes = draw_bounding_boxes(eval_inputs['image'], stage2_pred_bbs, color=(1., 1., 0.))    \n",
    "        # All outputs, combined with \n",
    "        all_boxes = draw_bounding_boxes(eval_inputs['image'], stage2_pred_bbs, color=(1., 0., 1.))\n",
    "        all_boxes = draw_bounding_boxes(all_boxes, shortcut_individuals, color=(1., 0., 1.))\n",
    "        # Return\n",
    "        images = tf.stack([gt_boxes, groups, shortcut_boxes, crops, stage2_boxes, all_boxes], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        ############## Session\n",
    "        session_creator = tf.train.ChiefSessionCreator(\n",
    "            checkpoint_dir=log_dir, config=tf.ConfigProto(allow_soft_placement=True))\n",
    "\n",
    "        # Start session\n",
    "        with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "            # evaluate\n",
    "            mean_aps, _, _ = eval_test(sess, 0)\n",
    "            print('Mean AP', np.mean(mean_aps))\n",
    "\n",
    "            # occupancy rate            \n",
    "            sess.run(eval_initializer)\n",
    "            aux = np.zeros((4,))\n",
    "            try:\n",
    "                while 1:\n",
    "                    aux += sess.run([occupancy_rate, coverage, num_nonempty_samples, num_samples])\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print('num samples:', int(aux[-1]))\n",
    "            print('avg. occupancy rate:', aux[0] / aux[-2])\n",
    "            print('avg. coverage:', aux[1] / aux[-2])\n",
    "\n",
    "            # viz\n",
    "            if output or display:\n",
    "                sess.run(eval_initializer)\n",
    "                im_ids_, images_ = sess.run([eval_inputs['im_id'], images])                                    \n",
    "                fig, axis = plt.subplots(batch_size, 6, figsize=(18, 3 * batch_size))\n",
    "                for i, (im_id, image) in enumerate(zip(im_ids_, images_)):\n",
    "                    axis[i][0].set_title('Ground-truth (%s)' % im_id, fontsize=8)\n",
    "                    axis[i][1].set_title(\n",
    "                        'Predicted groups (c > %.2f)' % viz_confidence_threshold, fontsize=8)\n",
    "                    axis[i][2].set_title('Individuals (c > %.2f)' % viz_confidence_threshold, fontsize=8)\n",
    "                    axis[i][3].set_title('Extracted crops (%d)' % test_num_crops, fontsize=8)\n",
    "                    axis[i][4].set_title(\n",
    "                        'Stage 2 outputs (c > %.2f)' % viz_confidence_threshold_2, fontsize=8)\n",
    "                    axis[i][5].set_title(\n",
    "                        'All predictions (c > %.2f)' % viz_confidence_threshold_2, fontsize=8)\n",
    "                    for j in range(6):\n",
    "                        axis[i][j].imshow(image[j])\n",
    "                        axis[i][j].set_axis_off()\n",
    "                fig.tight_layout()\n",
    "                if output:\n",
    "                    plt.savefig(os.path.join(config['log_dir'], 'prediction_example.png'), dpi=200)\n",
    "                if not display:\n",
    "                    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.42466 - map@0.75 = 0.05473\n",
      "num samples: 3281\n",
      "avg. occupancy rate: 4.433260393873085\n",
      "avg. coverage: 0.8007358196900389\n",
      "CPU times: user 12min 40s, sys: 1min 11s, total: 13min 52s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_odgi('run_logs/sdd/mobilenet_100_odgi_512_256/02-19_20-17/', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.34270 - map@0.75 = 0.04287\n",
      "num samples: 3281\n",
      "avg. occupancy rate: 4.416380118787121\n",
      "avg. coverage: 0.8049052227434049\n"
     ]
    }
   ],
   "source": [
    "evaluate_odgi('run_logs/sdd/mobilenet_100_odgi_512_128/02-20_10-54/', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.26494 - map@0.75 = 0.03185\n",
      "Mean AP 0.14839477205128015\n",
      "num samples: 3281\n",
      "avg. occupancy rate: 4.389809315411066\n",
      "avg. coverage: 0.8003934904089866\n"
     ]
    }
   ],
   "source": [
    "evaluate_odgi('run_logs/sdd/mobilenet_100_odgi_512_64/02-21_10-11/', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.29058 - map@0.75 = 0.03388\n",
      "num samples: 3281\n",
      "avg. occupancy rate: 4.162863394810878\n",
      "avg. coverage: 0.7965519690409271\n"
     ]
    }
   ],
   "source": [
    "evaluate_odgi('run_logs/sdd/mobilenet_100_odgi_256_128/02-20_10-54/', display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSCOCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 4952 test images at step 0: map@0.50 = 0.34899 - map@0.55 = 0.31521 - map@0.60 = 0.28145 - map@0.65 = 0.24314 - map@0.70 = 0.19962 - map@0.75 = 0.15593 - map@0.80 = 0.10675 - map@0.85 = 0.05529 - map@0.90 = 0.01919 - map@0.95 = 0.00276\n",
      "Mean AP 0.17283341361353483\n",
      "num samples: 5000\n",
      "avg. occupancy rate: 2.0785541195476576\n",
      "avg. coverage: 0.9620532007325254\n",
      "CPU times: user 6min 21s, sys: 31 s, total: 6min 52s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_odgi('run_logs/mscoco/mobilenet_100_odgi_224_128/02-27_15-29/', display=False, display_with_nms=True, \n",
    "              retrieval_iou_threshold=[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 4952 test images at step 0: map@0.50 = 0.41239 - map@0.55 = 0.38223 - map@0.60 = 0.34723 - map@0.65 = 0.30446 - map@0.70 = 0.25496 - map@0.75 = 0.20266 - map@0.80 = 0.14118 - map@0.85 = 0.08279 - map@0.90 = 0.02721 - map@0.95 = 0.00382\n",
      "Mean AP 0.21589320230875103\n",
      "num samples: 5000\n",
      "avg. occupancy rate: 2.666599353796446\n",
      "avg. coverage: 0.9807983072585936\n",
      "CPU times: user 12min 22s, sys: 45.9 s, total: 13min 8s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_odgi('run_logs/mscoco/mobilenet_100_odgi_416_224/02-27_16-00/', display=False, display_with_nms=True,\n",
    "                  retrieval_iou_threshold=[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test variables sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.34196 - map@0.75 = 0.03352\n",
      "Mean AP 0.1877356374196042\n",
      "num samples: 3281\n",
      "avg. occupancy rate: 4.1822444513910595\n",
      "avg. coverage: 0.7449909188144466\n"
     ]
    }
   ],
   "source": [
    "# Two optimizers\n",
    "evaluate_odgi('run_logs/sdd/tiny_yolo_v2_odgi_512_256/03-04_11-16/', share_variables=True, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 3199 test images at step 0: map@0.50 = 0.34225 - map@0.75 = 0.03835\n",
      "Mean AP 0.1903003157516878\n",
      "num samples: 3281\n",
      "avg. occupancy rate: 4.317911847452329\n",
      "avg. coverage: 0.7744852383832106\n"
     ]
    }
   ],
   "source": [
    "# Two optimizers, 5 epochs delay\n",
    "evaluate_odgi('run_logs/sdd/tiny_yolo_v2_odgi_512_256/03-04_18-00/', share_variables=True, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two optimizers, all batchnorm\n",
    "evaluate_odgi('run_logs/sdd/tiny_yolo_v2_odgi_512_256/03-05_11-28/', share_variables=True, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two optimizers, 25 epochs delay\n",
    "evaluate_odgi('run_logs/sdd/tiny_yolo_v2_odgi_512_256/03-05_13-19', share_variables=True, display=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
